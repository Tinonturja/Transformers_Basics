{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadaa06c-70fc-4cc0-8a29-b641052b7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import multi30k,Multi30k\n",
    "import torch\n",
    "from typing import Iterable, List\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import IMDB,PennTreebank\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa9e745-a9d6-4959-a26b-a3458bfbfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "train_iter, test_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a937360-069b-450d-9232-e90f35cc15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label,sample = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9626d762-4915-47c4-b773-8dce592879d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label,sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e8397d-5695-4c02-b07c-3f7ad8ee5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list =([label for label,_ in train_iter])\n",
    "text_list = ([text for _,text in train_iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da1e7fe-9975-4626-952a-163462e2ebb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac821e3b-2af2-4d70-9484-9af971f462fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daa66eb9-a850-456a-8f70-0f5c9b7e1e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I just saw DreamGirls yesterday, and I was REALLY underimpressed. Despite all the Oscar buzz, this is nothing special. Anyone who was really impressed by this film has never bothered to see any of the true movie musical classics. Except for Eddie Murphy\\'s great musical and dramatic performance, Dreamgirls is just a glorified TV movie with no style or flair. Just a bunch of amateurs singing AT each other!<br /><br />Now, the first half hour was good, but I was irritated at how Eddie Murphy\\'s terrific raveup performances were truncated and interrupted by montages. Those were easily the best songs and best performances in the film. And the \"rise to the top\" portion of the film was the only part of the film that had a consistent point of view or any momentum. The remaining hour and 45 minutes was a formless, rambling mess that was neither realistic nor fantastic enough to be interesting. It was also visually dull and included too many sound-alike tunes.<br /><br />Condon didn\\'t try to turn any of the tunes into big show pieces as I\\'d expected they would. Each number in the 2nd half was just one closeup after another of people \"singing\" AT each other. And the way they shot Hudson\\'s big \"love me\" number was criminal! Condon just shot her stomping around the stage--no drama at all! God it sucked!<br /><br />AND note to all involved--that \"sing-talking dialog\" stuff might work on stage, but it DOES NOT WORK IN MOVIES (see embarrassing failures of Evita and Phantom). All that \"I\\'ll teeeell youuuu something Efff-ieeee!\" crap should have been left on the editing room floor. Those aren\\'t \"songs.\"<br /><br />Again, the film--except for Eddie Murphy\\'s amazing performance--was nothing more than a glorified TV movie. There must have been megabucks behind the PR work for this film! I wonder how much money was spent to give it that pre-release \"one to beat\" Oscar buzz? As a whole this film was, except for Eddie, NOWHERE NEAR an Oscar caliber movie! (except for Eddie) I\\'d rank it right up there with Grease 2. BIG disappointment, especially after all the (very expen$I\\'ve) hype!',\n",
       " 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0,len(text_list))\n",
    "\n",
    "text_list[idx],label_list[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662332be-c0be-4593-9f39-cea907cdd7c0",
   "metadata": {},
   "source": [
    "The data has 12500 test sample data. Here each one is labelled as one. So each movie got a positive review somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee633eed-98d4-4ade-aafb-01ba48f1bab3",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6722de-e6cb-4c73-99bc-4c19731247c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, EOS_IDX = 0,1,2\n",
    "special_symbols = ['<unk>','<pad>','<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82555d7f-a1fa-4178-8f3d-b80607220c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_token(dataset):\n",
    "    for _,text in dataset:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create the vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_token(train_iter), specials = special_symbols,special_first=True)\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e5c863-e48e-4453-a190-5ee95c297e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to index, Index to text\n",
    "\n",
    "# input--> token; output--> index\n",
    "text_to_idx = lambda text: [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "# input --> index; output--> token\n",
    "idx_to_text = lambda seq_en: \" \".join([vocab.get_itos()[idx] for idx in seq_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9271315a-a236-42c9-a2de-5efb9359381c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it t ! or has my been'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([12,24,36,48,60,72,84],dtype = torch.int64)\n",
    "#index_to_text = idx_to_text([12,24,36,48,60,72,84])\n",
    "index_to_text = idx_to_text(a)\n",
    "\n",
    "index_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0f1cce-a605-4cf9-8108-c291bb86fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<|endoftext|>', '.', 'the', ',', 'a', 'and', \"'\", 'of']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = list(vocab.get_itos())[:10]\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0546cc3e-2ee1-4695-a64a-b9fa2cbf2af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> <pad> <|endoftext|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = idx_to_text(torch.tensor([0,1,2]))\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f2ec0-f865-474f-9143-4bfe01c0e853",
   "metadata": {},
   "source": [
    "## Collate Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ffc46-1041-4764-b7cf-21f18fa8328a",
   "metadata": {},
   "source": [
    "Collate function shapes how the dataloader perceives the data. To pass the data through the model each string should have equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d72b192-5202-4d74-8b3b-569e7e1c4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(block_size, text):\n",
    "    \"\"\"The goal of the function is to generate a training sample. The input and the target dataset. It's done because the model learns from the input\n",
    "    and tries to predict the output.\n",
    "    \n",
    "    Parameters(block_size,text):\n",
    "        block_size: actually indicates the context size. At how many tokens the model can look at once. \n",
    "        text: the full dataset. A list of long tokens\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    src_seq,trg_seq = [],[]\n",
    "    sample_len = len(text) # gives the length of the total length of the input\n",
    "\n",
    "    # Calculating the stopping point for randomly selecting a sample\n",
    "    # This ensures the selected sample doesn't exceed the text\n",
    "    random_sample_stop = sample_len - block_size\n",
    "\n",
    "    # random sampling should be starting in this limit\n",
    "\n",
    "    if random_sample_stop >=1:\n",
    "\n",
    "        # pick the starting point\n",
    "        random_start = torch.randint(0,random_sample_stop, size = (1,)).item()\n",
    "\n",
    "        stop = random_start + block_size\n",
    "\n",
    "        # Create the input and the target sequence\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop+1]\n",
    "\n",
    "\n",
    "\n",
    "    # Handle the case where the text sequence is exactly same as the context size\n",
    "    elif random_sample_stop <= 0:\n",
    "\n",
    "        random_start = 0\n",
    "        stop = sample_len\n",
    "\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop]\n",
    "\n",
    "        # Append an empty string to maintain the sequence alignment\n",
    "        trg_seq.append('<|endoftext|>')\n",
    "\n",
    "    return src_seq,trg_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72929ad2-160c-4362-aef2-060bb53332be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the training data tokens into a list\n",
    "BATCH_SIZE = 1 # for each batch its return a list of tokens which could be used for training\n",
    "\n",
    "batch_of_tokens = []\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    label,text = next(iter(train_iter))\n",
    "    batch_of_tokens.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "619092a1-d470-4290-9db2-4c31f884a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4847764-4b6b-4b43-8268-4a1c5f868fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how is the input and the output sequence would be feed to the training model\n",
    "\n",
    "# create the whole dataset for training of 100 tokens\n",
    "text = batch_of_tokens[0][0:100]\n",
    "block_size = 10\n",
    "\n",
    "src_seq, trg_seq = get_sample(block_size,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1104c172-bacc-41df-a368-cc482ef3ecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['.',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'focus',\n",
       "  'her',\n",
       "  'attentions',\n",
       "  'to'],\n",
       " ['in',\n",
       "  'particular',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'focus',\n",
       "  'her',\n",
       "  'attentions',\n",
       "  'to',\n",
       "  'making'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq,trg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb8e5eb3-14da-4e2e-8b37-58512fe69925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 14, 979, 68, 518, 10, 1216, 57, 12246, 10],\n",
       " [14, 979, 68, 518, 10, 1216, 57, 12246, 10, 233])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(src_seq),vocab(trg_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44993ecf-7e07-4db9-a83a-d87c34121c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n",
      "Source Sequence (Text): ['wanting', 'to', 'study', 'the', 'meat', 'and', 'potatoes', '(', 'no', 'pun']\n",
      "Source Sequence (Indices): [1798, 10, 2307, 4, 2876, 7, 14661, 29, 56, 4419]\n",
      "Source Sequence (Shape): 10\n",
      "Target Sequence (Text): ['to', 'study', 'the', 'meat', 'and', 'potatoes', '(', 'no', 'pun', 'intended']\n",
      "Target Sequence (Indices): [10, 2307, 4, 2876, 7, 14661, 29, 56, 4419, 1218]\n",
      "Target Sequence (Shape): 10\n",
      "Sample: 1\n",
      "Source Sequence (Text): ['between', 'asking', 'politicians', 'and', 'ordinary', 'denizens', 'of', 'stockholm', 'about', 'their']\n",
      "Source Sequence (Indices): [259, 1743, 7457, 7, 2318, 29828, 9, 16111, 52, 80]\n",
      "Source Sequence (Shape): 10\n",
      "Target Sequence (Text): ['asking', 'politicians', 'and', 'ordinary', 'denizens', 'of', 'stockholm', 'about', 'their', 'opinions']\n",
      "Target Sequence (Indices): [1743, 7457, 7, 2318, 29828, 9, 16111, 52, 80, 4554]\n",
      "Target Sequence (Shape): 10\n"
     ]
    }
   ],
   "source": [
    "src_batch,trg_batch = [],[]\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 2\n",
    "block_size = 10\n",
    "# Loop to create src batch and target batch\n",
    "for i in range(BATCH_SIZE):\n",
    "    _,text = next(iter(train_iter)) # Get the first sample every time, as we convert the train data iterable in every turn\n",
    "\n",
    "\n",
    "    # turn the text into tokenizer and then send them\n",
    "    text_tokens = tokenizer(text)\n",
    "\n",
    "    # Generate source and target tokens\n",
    "    src_tokens,trg_tokens = get_sample(block_size,text_tokens) # block_size is previously declared; block_size = 10\n",
    "\n",
    "    # Get the indices of that tokens\n",
    "    src_indices,trg_indices = vocab(src_tokens),vocab(trg_tokens)\n",
    "\n",
    "    # Turn the indices into tensors\n",
    "    src_sequence = torch.tensor(src_indices)\n",
    "    trg_sequence = torch.tensor(trg_indices)\n",
    "    \n",
    "\n",
    "    # print the output \n",
    "    print(f\"Sample: {i}\")\n",
    "    print(f\"Source Sequence (Text): {src_tokens}\")\n",
    "    print(f\"Source Sequence (Indices): {src_indices}\")\n",
    "    print(f\"Source Sequence (Shape): {len(src_tokens)}\")\n",
    "    print(f\"Target Sequence (Text): {trg_tokens}\")\n",
    "    print(f\"Target Sequence (Indices): {trg_indices}\")\n",
    "    print(f\"Target Sequence (Shape): {len(trg_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ec95a-2697-4e7c-8b67-13b70eb86544",
   "metadata": {},
   "source": [
    "## Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d23e5385-6202-47f9-87f2-1d99fb8e9f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cuda'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3a584cb-4e9c-4510-8e90-7414129eb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 30\n",
    "\n",
    "def collate_batch(batch):\n",
    "    src_batch,trg_batch = [],[]\n",
    "\n",
    "    for _,text in batch:\n",
    "\n",
    "        tokens = tokenizer(text)\n",
    "\n",
    "        src_tokens,trg_tokens = get_sample(BLOCK_SIZE,tokens)\n",
    "\n",
    "        src_indices,trg_indices = vocab(src_tokens),vocab(trg_tokens)\n",
    "\n",
    "        src_seq,trg_seq = torch.tensor(src_indices,dtype = torch.int64),torch.tensor(trg_indices,dtype = torch.int64)\n",
    "\n",
    "        src_batch.append(src_seq)\n",
    "        trg_batch.append(trg_seq)\n",
    "\n",
    "\n",
    "    src_batch = pad_sequence(src_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "    trg_batch = pad_sequence(trg_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "\n",
    "    return src_batch.to(DEVICE),trg_batch.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd57b2-30df-40b9-80ac-b856a92d5434",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dcb59e1-e6ce-4a85-bcb5-d09047012cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "train_dataloader = DataLoader(train_iter,\n",
    "                       batch_size = BATCH_SIZE,\n",
    "                       shuffle = True,\n",
    "                       collate_fn = collate_batch) # collate batch will define how the data will be retuerned\n",
    "\n",
    "test_dataloader = DataLoader(test_iter,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = True,\n",
    "                            collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9032cc-89e4-47ea-bdc1-b48da0da1a93",
   "metadata": {},
   "source": [
    "## Iterating Through Data Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddae662f-60f9-4f83-840f-b8835c55a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 0\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: had better effects when they aired their first episodes in 1993 . that was 4 years before sg-1 started . and they did ' nt have the apparent two million\n",
      "\n",
      "\n",
      "Target: better effects when they aired their first episodes in 1993 . that was 4 years before sg-1 started . and they did ' nt have the apparent two million dollar\n",
      "\n",
      "\n",
      "sample: 0\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: as other male reviewers have , i did enjoy seeing karen allen ' s cute , petite body . i ' ll give the movie four stars two of them\n",
      "\n",
      "\n",
      "Target: other male reviewers have , i did enjoy seeing karen allen ' s cute , petite body . i ' ll give the movie four stars two of them are\n",
      "\n",
      "\n",
      "sample: 1\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: historically inaccurate and ridiculous that he refused , and also demanded they stop using his name as a source ( it embarrassed him to think people would think he was\n",
      "\n",
      "\n",
      "Target: inaccurate and ridiculous that he refused , and also demanded they stop using his name as a source ( it embarrassed him to think people would think he was involved\n",
      "\n",
      "\n",
      "sample: 1\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: all that , crazy , fat ethel has lost a portion of her girth . i mean , honestly , is this some kind of sick joke ? ! ?\n",
      "\n",
      "\n",
      "Target: that , crazy , fat ethel has lost a portion of her girth . i mean , honestly , is this some kind of sick joke ? ! ? thank\n",
      "\n",
      "\n",
      "sample: 2\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: have the evil charisma of hitler , saddam or bin laden but he never comes across as anything more than a petulant truculent teenager and it ' s impossible to\n",
      "\n",
      "\n",
      "Target: the evil charisma of hitler , saddam or bin laden but he never comes across as anything more than a petulant truculent teenager and it ' s impossible to believe\n",
      "\n",
      "\n",
      "sample: 2\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: that they had to put something in to make it half way worthwhile at all . so it just becomes yet another contrivance . do yourself a favour and give\n",
      "\n",
      "\n",
      "Target: they had to put something in to make it half way worthwhile at all . so it just becomes yet another contrivance . do yourself a favour and give this\n",
      "\n",
      "\n",
      "sample: 3\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: hillbillies . there were quite a bit of alarming signs indicating us that this sequel would be a horrendous failure as well . the remake came out barely one year\n",
      "\n",
      "\n",
      "Target: . there were quite a bit of alarming signs indicating us that this sequel would be a horrendous failure as well . the remake came out barely one year ago\n",
      "\n",
      "\n",
      "sample: 3\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: movie . every scene has at least one awkward or misplaced quote . for example , in one scene , victor tries to complain about not being able to have\n",
      "\n",
      "\n",
      "Target: . every scene has at least one awkward or misplaced quote . for example , in one scene , victor tries to complain about not being able to have nieces\n",
      "\n",
      "\n",
      "sample: 4\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: contained a lot of no-brainer comedy to a point where it just got boring . some of the audience seemed to find it funny but i like more intelligent humor\n",
      "\n",
      "\n",
      "Target: a lot of no-brainer comedy to a point where it just got boring . some of the audience seemed to find it funny but i like more intelligent humor .\n",
      "\n",
      "\n",
      "sample: 4\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: resorts to voice-over narration . in this case it ' s used in the worst possible sense which is to give information that otherwise we ' d never glean .\n",
      "\n",
      "\n",
      "Target: to voice-over narration . in this case it ' s used in the worst possible sense which is to give information that otherwise we ' d never glean . in\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = iter(train_dataloader)\n",
    "\n",
    "for sample in range(5):\n",
    "    src, tgr = next(dataset)\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        print(f\"sample: {sample}\")\n",
    "        print(f\"Source shape: {src.shape}\")\n",
    "        print(f\"source: {idx_to_text(src[:,i])}\") # take the indices as the intput and return the word as the output\n",
    "        print(\"\\n\")\n",
    "        print(f\"Target: {idx_to_text(tgr[:,i])}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7083e-ab92-411b-9940-2fb3530c9b5d",
   "metadata": {},
   "source": [
    "## **MASKING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb5739-f61e-4d93-9a02-b2fcc0b5ee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22145155-405d-46c5-a476-c5b492b45888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760adca6-915d-4c1b-bc09-d0781294474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4dddb-7772-4a25-a369-f03ceae2a919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
