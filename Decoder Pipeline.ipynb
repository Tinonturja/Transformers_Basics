{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadaa06c-70fc-4cc0-8a29-b641052b7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import multi30k,Multi30k\n",
    "import torch\n",
    "from typing import Iterable, List\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import IMDB,PennTreebank\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa9e745-a9d6-4959-a26b-a3458bfbfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "train_iter, test_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a937360-069b-450d-9232-e90f35cc15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label,sample = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9626d762-4915-47c4-b773-8dce592879d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label,sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e8397d-5695-4c02-b07c-3f7ad8ee5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list =([label for label,_ in train_iter])\n",
    "text_list = ([text for _,text in train_iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da1e7fe-9975-4626-952a-163462e2ebb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac821e3b-2af2-4d70-9484-9af971f462fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa66eb9-a850-456a-8f70-0f5c9b7e1e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I can't believe that in the 34 prior comments, nobody mentioned that this film is a blatant rip-off of Born Yesterday. A man is hired to bring an ostensibly dumb blonde up to the requirements of a gangster. Hired gun and blonde fall in love and live happily ever after. Gangster is left in the lurch. But Born Yesterday was an intelligent treatment whereas this is just so much fluff. Technicolor transfer to DVD is deplorable. Natalie Kalmus would be rolling over in her grave. Check out the paperboy. Recognize him? But, it's historically interesting to see the roots of Rock 'n Roll. Also interesting is Ewell's introduction to CinemaScope, a new format at the time.\",\n",
       " 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0,len(text_list))\n",
    "\n",
    "text_list[idx],label_list[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662332be-c0be-4593-9f39-cea907cdd7c0",
   "metadata": {},
   "source": [
    "The data has 12500 test sample data. Here each one is labelled as one. So each movie got a positive review somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee633eed-98d4-4ade-aafb-01ba48f1bab3",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6722de-e6cb-4c73-99bc-4c19731247c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, EOS_IDX = 0,1,2\n",
    "special_symbols = ['<unk>','<pad>','<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82555d7f-a1fa-4178-8f3d-b80607220c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_token(dataset):\n",
    "    for _,text in dataset:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create the vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_token(train_iter), specials = special_symbols,special_first=True)\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e5c863-e48e-4453-a190-5ee95c297e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to index, Index to text\n",
    "\n",
    "# input--> token; output--> index\n",
    "text_to_idx = lambda text: [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "# input --> index; output--> token\n",
    "idx_to_text = lambda seq_en: \" \".join([vocab.get_itos()[idx] for idx in seq_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0f1cce-a605-4cf9-8108-c291bb86fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<|endoftext|>', '.', 'the', ',', 'a', 'and', \"'\", 'of']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = list(vocab.get_itos())[:10]\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0546cc3e-2ee1-4695-a64a-b9fa2cbf2af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> <pad> <|endoftext|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = idx_to_text(torch.tensor([0,1,2]))\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f2ec0-f865-474f-9143-4bfe01c0e853",
   "metadata": {},
   "source": [
    "## Collate Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ffc46-1041-4764-b7cf-21f18fa8328a",
   "metadata": {},
   "source": [
    "Collate function shapes how the dataloader perceives the data. To pass the data through the model each string should have equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d72b192-5202-4d74-8b3b-569e7e1c4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(block_size, text):\n",
    "    \"\"\"The goal of the function is to generate a training sample. The input and the target dataset. It's done because the model learns from the input\n",
    "    and tries to predict the output.\n",
    "    \n",
    "    Parameters(block_size,text):\n",
    "        block_size: actually indicates the context size. At how many tokens the model can look at once. \n",
    "        text: the full dataset. A list of long tokens\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    src_seq,trg_seq = [],[]\n",
    "    sample_len = len(text) # gives the length of the total length of the input\n",
    "\n",
    "    # Calculating the stopping point for randomly selecting a sample\n",
    "    # This ensures the selected sample doesn't exceed the text\n",
    "    random_sample_stop = sample_len - block_size\n",
    "\n",
    "    # random sampling should be starting in this limit\n",
    "\n",
    "    if random_sample_stop >=1:\n",
    "\n",
    "        # pick the starting point\n",
    "        random_start = torch.randint(0,random_sample_stop, size = (1,)).item()\n",
    "\n",
    "        stop = random_start + block_size\n",
    "\n",
    "        # Create the input and the target sequence\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop+1]\n",
    "\n",
    "\n",
    "\n",
    "    # Handle the case where the text sequence is exactly same as the context size\n",
    "    elif random_sample_stop <= 0:\n",
    "\n",
    "        random_start = 0\n",
    "        stop = sample_len\n",
    "\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop]\n",
    "\n",
    "        # Append an empty string to maintain the sequence alignment\n",
    "        trg_seq.append('<|endoftext|>')\n",
    "\n",
    "    return src_seq,trg_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72929ad2-160c-4362-aef2-060bb53332be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the training data tokens into a list\n",
    "BATCH_SIZE = 1 # for each batch its return a list of tokens which could be used for training\n",
    "\n",
    "batch_of_tokens = []\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    label,text = next(iter(train_iter))\n",
    "    batch_of_tokens.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "619092a1-d470-4290-9db2-4c31f884a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4847764-4b6b-4b43-8268-4a1c5f868fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how is the input and the output sequence would be feed to the training model\n",
    "\n",
    "# create the whole dataset for training of 100 tokens\n",
    "text = batch_of_tokens[0][0:100]\n",
    "block_size = 10\n",
    "\n",
    "src_seq, trg_seq = get_sample(block_size,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1104c172-bacc-41df-a368-cc482ef3ecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['at', 'first', 'it', 'was', 'seized', 'by', 'u', '.', 's', '.'],\n",
       " ['first', 'it', 'was', 'seized', 'by', 'u', '.', 's', '.', 'customs'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq,trg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb8e5eb3-14da-4e2e-8b37-58512fe69925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([38, 98, 12, 18, 17608, 46, 1466, 3, 17, 3],\n",
       " [98, 12, 18, 17608, 46, 1466, 3, 17, 3, 11063])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(src_seq),vocab(trg_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44993ecf-7e07-4db9-a83a-d87c34121c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n",
      "Source Sequence (Text): ['fact', 'that', 'any', 'sex', 'shown', 'in', 'the', 'film', 'is', 'shown']\n",
      "Source Sequence (Indices): [198, 16, 93, 338, 693, 14, 4, 25, 11, 693]\n",
      "Source Sequence (Shape): 10\n",
      "Target Sequence (Text): ['that', 'any', 'sex', 'shown', 'in', 'the', 'film', 'is', 'shown', 'for']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tgt_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource Sequence (Shape): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(src_tokens)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget Sequence (Text): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrg_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget Sequence (Indices): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtgt_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget Sequence (Shape): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tgt_tokens)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tgt_indices' is not defined"
     ]
    }
   ],
   "source": [
    "src_batch,trg_batch = [],[]\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 2\n",
    "block_size = 10\n",
    "# Loop to create src batch and target batch\n",
    "for i in range(BATCH_SIZE):\n",
    "    _,text = next(iter(train_iter)) # Get the first sample every time, as we convert the train data iterable in every turn\n",
    "\n",
    "\n",
    "    # turn the text into tokenizer and then send them\n",
    "    text_tokens = tokenizer(text)\n",
    "\n",
    "    # Generate source and target tokens\n",
    "    src_tokens,trg_tokens = get_sample(block_size,text_tokens) # block_size is previously declared; block_size = 10\n",
    "\n",
    "    # Get the indices of that tokens\n",
    "    src_indices,trg_indices = vocab(src_tokens),vocab(trg_tokens)\n",
    "\n",
    "    # Turn the indices into tensors\n",
    "    src_sequence = torch.tensor(src_indices)\n",
    "    trg_sequence = torch.tensor(trg_indices)\n",
    "    \n",
    "\n",
    "    # print the output \n",
    "    print(f\"Sample: {i}\")\n",
    "    print(f\"Source Sequence (Text): {src_tokens}\")\n",
    "    print(f\"Source Sequence (Indices): {src_indices}\")\n",
    "    print(f\"Source Sequence (Shape): {len(src_tokens)}\")\n",
    "    print(f\"Target Sequence (Text): {trg_tokens}\")\n",
    "    print(f\"Target Sequence (Indices): {t_indices}\")\n",
    "    print(f\"Target Sequence (Shape): {len(tgt_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e32aa-23c5-4d03-a960-b7807c17a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab(['i','don','t','give','a','flying','fuck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049d833-149a-4783-96e6-02970af4b8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a584cb-4e9c-4510-8e90-7414129eb66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb59e1-e6ce-4a85-bcb5-d09047012cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53532b-4245-4b73-9e79-c22eb6673b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae662f-60f9-4f83-840f-b8835c55a7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719c49f-8d52-4729-b491-e139a9339626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd90c30-acde-43eb-ad4b-544e273d9d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4479406-9b15-4b8c-92d7-0ca1f5b4ed08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b62ec-d172-4b79-86ab-4165d5acabfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195c55b-6c93-4f40-8e9d-138407592aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb5739-f61e-4d93-9a02-b2fcc0b5ee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22145155-405d-46c5-a476-c5b492b45888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760adca6-915d-4c1b-bc09-d0781294474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4dddb-7772-4a25-a369-f03ceae2a919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
