{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadaa06c-70fc-4cc0-8a29-b641052b7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import multi30k,Multi30k\n",
    "import torch\n",
    "from typing import Iterable, List\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import IMDB,PennTreebank\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa9e745-a9d6-4959-a26b-a3458bfbfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "train_iter, test_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a937360-069b-450d-9232-e90f35cc15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label,sample = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9626d762-4915-47c4-b773-8dce592879d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label,sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e8397d-5695-4c02-b07c-3f7ad8ee5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list =([label for label,_ in train_iter])\n",
    "text_list = ([text for _,text in train_iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da1e7fe-9975-4626-952a-163462e2ebb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac821e3b-2af2-4d70-9484-9af971f462fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa66eb9-a850-456a-8f70-0f5c9b7e1e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('One of the more \\'literate\\' Lone Stars, with time spent on character development and interaction, dialog and acting business. The opening scene sets the stage (literally) for the personalities of the gambler, Kansas Charlie (Eddy Chandler), and his buddy, John Scott (John Wayne) the rodeo (say Roh-Day-oh) star, both of whom are slightly randy. The film follows their adventures, as they try to best each other in the pursuit of the Mexican Juanita, and later in their pursuit of perky Mary Kornman, who has the inevitable evil brother (though he\\'d been led astray by the real villain, and wants to repent). And oh, of course, they\\'re being wrongly accused of two crimes and have to serve jail time before escaping and being exonerated at the end.<br /><br />The high point is Scott continually and deliberately ogling Mary\\'s butt in her grocery store, and knocking away the ladder she\\'s standing on so he can catch her and grab her as she falls. It all seems a little contemporary for a 30s western, but it sounds better than it actually is. <br /><br />Sadly, the exciting action elements we find in many other Lone Stars are sorely missing here. No Yakima Canutt. Cheap and bad uses of stock footage of riders falling off horses. No George Hayes. Tedious Stooge-like bi-play between Scott and Charlie, with Charlie swinging at Scott, Scott stomping on his foot and then punching him (repeated two more times!). The skilled Paul Fix is underused. Eddy Chandler himself, here in his big star turn, is not really believable as a randy side kick. The villain looks too old and fat. So does Chandler, who spent his later career in 300 more movies as an uncredited meatloaf. Mary Kornman, of the twenties \"Our Gang\" (see \\'Mary, Queen of Tots\\' 1925) is cute in her scenes with John Wayne, but that\\'s about it for this one. Seeds of a better western lie buried here.<br /><br />P.S. The ultra-short colorized version, which looks good, moves along so fast, it\\'s over if you blink more than once. Thankfully though, the embarrassing scenes with Eddy Chandler have been cut.',\n",
       " 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0,len(text_list))\n",
    "\n",
    "text_list[idx],label_list[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662332be-c0be-4593-9f39-cea907cdd7c0",
   "metadata": {},
   "source": [
    "The data has 12500 test sample data. Here each one is labelled as one. So each movie got a positive review somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee633eed-98d4-4ade-aafb-01ba48f1bab3",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6722de-e6cb-4c73-99bc-4c19731247c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, EOS_IDX = 0,1,2\n",
    "special_symbols = ['<unk>','<pad>','<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82555d7f-a1fa-4178-8f3d-b80607220c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_token(dataset):\n",
    "    for _,text in dataset:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create the vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_token(train_iter), specials = special_symbols,special_first=True)\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e5c863-e48e-4453-a190-5ee95c297e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to index, Index to text\n",
    "\n",
    "# input--> token; output--> index\n",
    "text_to_idx = lambda text: [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "# input --> index; output--> token\n",
    "idx_to_text = lambda seq_en: \" \".join([vocab.get_itos()[idx] for idx in seq_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9271315a-a236-42c9-a2de-5efb9359381c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it t ! or has my been'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([12,24,36,48,60,72,84],dtype = torch.int64)\n",
    "#index_to_text = idx_to_text([12,24,36,48,60,72,84])\n",
    "index_to_text = idx_to_text(a)\n",
    "\n",
    "index_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0f1cce-a605-4cf9-8108-c291bb86fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<|endoftext|>', '.', 'the', ',', 'a', 'and', \"'\", 'of']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = list(vocab.get_itos())[:10]\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0546cc3e-2ee1-4695-a64a-b9fa2cbf2af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> <pad> <|endoftext|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = idx_to_text(torch.tensor([0,1,2]))\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f2ec0-f865-474f-9143-4bfe01c0e853",
   "metadata": {},
   "source": [
    "## Collate Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ffc46-1041-4764-b7cf-21f18fa8328a",
   "metadata": {},
   "source": [
    "Collate function shapes how the dataloader perceives the data. To pass the data through the model each string should have equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d72b192-5202-4d74-8b3b-569e7e1c4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(block_size, text):\n",
    "    \"\"\"The goal of the function is to generate a training sample. The input and the target dataset. It's done because the model learns from the input\n",
    "    and tries to predict the output.\n",
    "    \n",
    "    Parameters(block_size,text):\n",
    "        block_size: actually indicates the context size. At how many tokens the model can look at once. \n",
    "        text: the full dataset. A list of long tokens\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    src_seq,trg_seq = [],[]\n",
    "    sample_len = len(text) # gives the length of the total length of the input\n",
    "\n",
    "    # Calculating the stopping point for randomly selecting a sample\n",
    "    # This ensures the selected sample doesn't exceed the text\n",
    "    random_sample_stop = sample_len - block_size\n",
    "\n",
    "    # random sampling should be starting in this limit\n",
    "\n",
    "    if random_sample_stop >=1:\n",
    "\n",
    "        # pick the starting point\n",
    "        random_start = torch.randint(0,random_sample_stop, size = (1,)).item()\n",
    "\n",
    "        stop = random_start + block_size\n",
    "\n",
    "        # Create the input and the target sequence\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop+1]\n",
    "\n",
    "\n",
    "\n",
    "    # Handle the case where the text sequence is exactly same as the context size\n",
    "    elif random_sample_stop <= 0:\n",
    "\n",
    "        random_start = 0\n",
    "        stop = sample_len\n",
    "\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop]\n",
    "\n",
    "        # Append an empty string to maintain the sequence alignment\n",
    "        trg_seq.append('<|endoftext|>')\n",
    "\n",
    "    return src_seq,trg_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72929ad2-160c-4362-aef2-060bb53332be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the training data tokens into a list\n",
    "BATCH_SIZE = 1 # for each batch its return a list of tokens which could be used for training\n",
    "\n",
    "batch_of_tokens = []\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    label,text = next(iter(train_iter))\n",
    "    batch_of_tokens.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "619092a1-d470-4290-9db2-4c31f884a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4847764-4b6b-4b43-8268-4a1c5f868fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how is the input and the output sequence would be feed to the training model\n",
    "\n",
    "# create the whole dataset for training of 100 tokens\n",
    "text = batch_of_tokens[0][0:100]\n",
    "block_size = 10\n",
    "\n",
    "src_seq, trg_seq = get_sample(block_size,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1104c172-bacc-41df-a368-cc482ef3ecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it',\n",
       "  'when'],\n",
       " ['because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it',\n",
       "  'when',\n",
       "  'it'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq,trg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb8e5eb3-14da-4e2e-8b37-58512fe69925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1024, 87, 9, 40, 4, 7333, 16, 2975, 12, 66],\n",
       " [87, 9, 40, 4, 7333, 16, 2975, 12, 66, 12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(src_seq),vocab(trg_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44993ecf-7e07-4db9-a83a-d87c34121c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n",
      "Source Sequence (Text): ['controversial', 'i', 'really', 'had', 'to', 'see', 'this', 'for', 'myself', '.']\n",
      "Source Sequence (Indices): [3535, 13, 69, 70, 10, 77, 15, 20, 479, 3]\n",
      "Source Sequence (Shape): 10\n",
      "Target Sequence (Text): ['i', 'really', 'had', 'to', 'see', 'this', 'for', 'myself', '.', 'the']\n",
      "Target Sequence (Indices): [13, 69, 70, 10, 77, 15, 20, 479, 3, 4]\n",
      "Target Sequence (Shape): 10\n",
      "Sample: 1\n",
      "Source Sequence (Text): ['scenes', 'in', 'his', 'films', '.', 'i', 'do', 'commend', 'the', 'filmmakers']\n",
      "Source Sequence (Indices): [144, 14, 39, 129, 3, 13, 81, 11638, 4, 839]\n",
      "Source Sequence (Shape): 10\n",
      "Target Sequence (Text): ['in', 'his', 'films', '.', 'i', 'do', 'commend', 'the', 'filmmakers', 'for']\n",
      "Target Sequence (Indices): [14, 39, 129, 3, 13, 81, 11638, 4, 839, 20]\n",
      "Target Sequence (Shape): 10\n"
     ]
    }
   ],
   "source": [
    "src_batch,trg_batch = [],[]\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 2\n",
    "block_size = 10\n",
    "# Loop to create src batch and target batch\n",
    "for i in range(BATCH_SIZE):\n",
    "    _,text = next(iter(train_iter)) # Get the first sample every time, as we convert the train data iterable in every turn\n",
    "\n",
    "\n",
    "    # turn the text into tokenizer and then send them\n",
    "    text_tokens = tokenizer(text)\n",
    "\n",
    "    # Generate source and target tokens\n",
    "    src_tokens,trg_tokens = get_sample(block_size,text_tokens) # block_size is previously declared; block_size = 10\n",
    "\n",
    "    # Get the indices of that tokens\n",
    "    src_indices,trg_indices = vocab(src_tokens),vocab(trg_tokens)\n",
    "\n",
    "    # Turn the indices into tensors\n",
    "    src_sequence = torch.tensor(src_indices)\n",
    "    trg_sequence = torch.tensor(trg_indices)\n",
    "    \n",
    "\n",
    "    # print the output \n",
    "    print(f\"Sample: {i}\")\n",
    "    print(f\"Source Sequence (Text): {src_tokens}\")\n",
    "    print(f\"Source Sequence (Indices): {src_indices}\")\n",
    "    print(f\"Source Sequence (Shape): {len(src_tokens)}\")\n",
    "    print(f\"Target Sequence (Text): {trg_tokens}\")\n",
    "    print(f\"Target Sequence (Indices): {trg_indices}\")\n",
    "    print(f\"Target Sequence (Shape): {len(trg_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ec95a-2697-4e7c-8b67-13b70eb86544",
   "metadata": {},
   "source": [
    "## Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d23e5385-6202-47f9-87f2-1d99fb8e9f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cuda'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3a584cb-4e9c-4510-8e90-7414129eb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 30\n",
    "\n",
    "def collate_batch(batch):\n",
    "    src_batch,trg_batch = [],[]\n",
    "\n",
    "    for _,text in batch:\n",
    "\n",
    "        tokens = tokenizer(text)\n",
    "\n",
    "        src_tokens,trg_tokens = get_sample(BLOCK_SIZE,tokens)\n",
    "\n",
    "        src_indices,trg_indices = vocab(src_tokens),vocab(trg_tokens)\n",
    "\n",
    "        src_seq,trg_seq = torch.tensor(src_indices,dtype = torch.int64),torch.tensor(trg_indices,dtype = torch.int64)\n",
    "\n",
    "        src_batch.append(src_seq)\n",
    "        trg_batch.append(trg_seq)\n",
    "\n",
    "\n",
    "    src_batch = pad_sequence(src_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "    trg_batch = pad_sequence(trg_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "\n",
    "    return src_batch.to(DEVICE),trg_batch.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd57b2-30df-40b9-80ac-b856a92d5434",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dcb59e1-e6ce-4a85-bcb5-d09047012cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "train_dataloader = DataLoader(train_iter,\n",
    "                       batch_size = BATCH_SIZE,\n",
    "                       shuffle = True,\n",
    "                       collate_fn = collate_batch) # collate batch will define how the data will be retuerned\n",
    "\n",
    "test_dataloader = DataLoader(test_iter,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = True,\n",
    "                            collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9032cc-89e4-47ea-bdc1-b48da0da1a93",
   "metadata": {},
   "source": [
    "## Iterating Through Data Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddae662f-60f9-4f83-840f-b8835c55a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 0\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: . for 1931 , maybe . for 2004 , not acceptable . some of the actors performed well . sadly , the indians always get the short end in these\n",
      "\n",
      "\n",
      "Target: for 1931 , maybe . for 2004 , not acceptable . some of the actors performed well . sadly , the indians always get the short end in these early\n",
      "\n",
      "\n",
      "sample: 0\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: mcdowell isn ' t much of an actress to begin with , but given the non-existent plot ( i hate to even refer to it as a plot ) in\n",
      "\n",
      "\n",
      "Target: isn ' t much of an actress to begin with , but given the non-existent plot ( i hate to even refer to it as a plot ) in this\n",
      "\n",
      "\n",
      "sample: 1\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: ' t be surprised if the father of the baby had about eight girlfriends in the first edition of the script . stacy ' s ( the carrier of the\n",
      "\n",
      "\n",
      "Target: t be surprised if the father of the baby had about eight girlfriends in the first edition of the script . stacy ' s ( the carrier of the baby\n",
      "\n",
      "\n",
      "sample: 1\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: dirty . the closest thing to a sex scene in the movie has sayuri wrinkling up her nose and grimacing with distaste for five seconds as if the man trying\n",
      "\n",
      "\n",
      "Target: . the closest thing to a sex scene in the movie has sayuri wrinkling up her nose and grimacing with distaste for five seconds as if the man trying to\n",
      "\n",
      "\n",
      "sample: 2\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: why they were so striking in such a less-than-subtle way . maybe he intends to remind us of the giants whose time had passed -- all he really does is\n",
      "\n",
      "\n",
      "Target: they were so striking in such a less-than-subtle way . maybe he intends to remind us of the giants whose time had passed -- all he really does is remind\n",
      "\n",
      "\n",
      "sample: 2\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: child prostitution ring . this film incorporates all of the worst stereotypes you could imagine in a worst-case scenario that exists only in the minds of hollywood , the press\n",
      "\n",
      "\n",
      "Target: prostitution ring . this film incorporates all of the worst stereotypes you could imagine in a worst-case scenario that exists only in the minds of hollywood , the press and\n",
      "\n",
      "\n",
      "sample: 3\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: and the movie are humongous . very important elements , which made the whole thing plausible are just written out or changed to bad . if the plot sounds interesting\n",
      "\n",
      "\n",
      "Target: the movie are humongous . very important elements , which made the whole thing plausible are just written out or changed to bad . if the plot sounds interesting to\n",
      "\n",
      "\n",
      "sample: 3\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: worst one of them all . it doesn ' t deserve the name american pie . they should have stopped at the wedding . this movie feels like just a\n",
      "\n",
      "\n",
      "Target: one of them all . it doesn ' t deserve the name american pie . they should have stopped at the wedding . this movie feels like just a stupid\n",
      "\n",
      "\n",
      "sample: 4\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: me a little while ago . i wish i never picked this movie ! after i watched it i felt even more sick and i wanted to throw up .\n",
      "\n",
      "\n",
      "Target: a little while ago . i wish i never picked this movie ! after i watched it i felt even more sick and i wanted to throw up . afterwords\n",
      "\n",
      "\n",
      "sample: 4\n",
      "Source shape: torch.Size([30, 2])\n",
      "source: i don ' t care , it ' s too late . the supporting cast was sincere and well played--i felt for *them ! *--and the gay best friend was\n",
      "\n",
      "\n",
      "Target: don ' t care , it ' s too late . the supporting cast was sincere and well played--i felt for *them ! *--and the gay best friend was wonderful\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = iter(train_dataloader)\n",
    "\n",
    "for sample in range(5):\n",
    "    src, tgr = next(dataset)\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        print(f\"sample: {sample}\")\n",
    "        print(f\"Source shape: {src.shape}\")\n",
    "        print(f\"source: {idx_to_text(src[:,i])}\") # take the indices as the intput and return the word as the output\n",
    "        print(\"\\n\")\n",
    "        print(f\"Target: {idx_to_text(tgr[:,i])}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7083e-ab92-411b-9940-2fb3530c9b5d",
   "metadata": {},
   "source": [
    "## **MASKING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081ed33-5c4b-4476-8bfe-9aa918c69515",
   "metadata": {},
   "source": [
    "Create masking so that the decoder while predicts the next word can only take words before the output words as the context, not the whole dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7bb5739-f61e-4d93-9a02-b2fcc0b5ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sqr_mask(sz,device = DEVICE):\n",
    "    mask = (torch.triu(torch.ones((sz,sz),device = device))==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22145155-405d-46c5-a476-c5b492b45888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf],\n",
       "        [0., 0., -inf],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,3)\n",
    "a = (torch.triu(a)==1).transpose(0,1)\n",
    "a = a.float().masked_fill( a ==0,float('-inf')).masked_fill(a ==1,float(0.0))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "760adca6-915d-4c1b-bc09-d0781294474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(sz,device):\n",
    "    mask = (torch.triu(torch.ones((sz,sz),device =device))==1).transpose(0,1)\n",
    "    mask = mask.float().masked_fill(mask ==0,float('-inf')).masked_fill(mask==1,float(0.0))\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba4dddb-7772-4a25-a369-f03ceae2a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src,device = DEVICE):\n",
    "    src_seq_len = src.shape[0]\n",
    "    src_mask = generate_mask(src_seq_len,device = DEVICE)\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0,1)\n",
    "    return src_mask,src_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f743b27a-da0c-4ee6-acf4-8dbb7bfb6f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., -inf, -inf, -inf, -inf],\n",
       "         [0., 0., -inf, -inf, -inf],\n",
       "         [0., 0., 0., -inf, -inf],\n",
       "         [0., 0., 0., 0., -inf],\n",
       "         [0., 0., 0., 0., 0.]], device='mps:0'),\n",
       " tensor([[False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test\n",
    "src_t = torch.rand(5,5)\n",
    "m =create_mask(src_t,device = DEVICE)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322e0ea-b453-4200-b75f-cd0541b45681",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25d8889a-c7d1-4372-8f8a-09a04f1508e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                emb_dim: int,\n",
    "                dropout: float,\n",
    "                maxlen: int = 5000):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        den = torch.exp(-torch.arange(0,emb_dim,2)*math.log(10000)/emb_dim)\n",
    "\n",
    "        pos = torch.arange(0,maxlen).reshape(maxlen,1)\n",
    "\n",
    "        pos_embedding = torch.zeros(size = (maxlen,emb_dim))\n",
    "\n",
    "\n",
    "        pos_embedding[:,0::2] = torch.sin(pos*den)\n",
    "        pos_embedding[:,1::2] = torch.cos(pos*den)\n",
    "\n",
    "\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer('pos_embedding',pos_embedding)\n",
    "\n",
    "    def forward(self,token_embedding):\n",
    "        return self.dropout(token_embedding+self.pos_embedding[:token_embedding.size(0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646b7aa-bddf-4e05-bb20-486f7cfbf22c",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90f9331a-9857-40b9-ad2c-90a83edb0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                vocab_size,\n",
    "                emb_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.embedding(vocab_size,emb_dim)\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def forward(self,tokens):\n",
    "        return self.embedding(tokens.long())*math.sqrt(self.emb_dim)\n",
    "        \"\"\"PyTorch nn.Embedding expects input as LongTensor (i.e., dtype=torch.int64).\n",
    "        This ensures that the token indices are valid integer indices for lookup.\n",
    "        If your tokens are accidentally float32, you'll get a type error.\"\"\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66220284-438c-4165-831a-b1b747c1861a",
   "metadata": {},
   "source": [
    "## Custom GPT Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ab7fd-c946-41d1-8d85-77d458c4ea19",
   "metadata": {},
   "source": [
    "* Initialization(init): embedding_dimension, vocab_size, num_heads, num_layers, max_sequence_length, and dropout\n",
    "* lm_head: Generates logits over the vocabulary\n",
    "\n",
    "* weight_initialization: Initializes the weights for better training convergence. The Xavier uniform initialization is used, which is a common practice for initializing weights in deep learning.\n",
    "* Decoder: method currently functions the forward pass, through the transformer encoder layers, followed by the generation of logits for the language modeling task.\n",
    "1) got the output from the transformer encoder layers\n",
    "2) Generation of logits for the language modelling task\n",
    "\n",
    "* Forward Pass: This method is similar to Decoder method, and defines the forward computation of the model. It produces the input through embedding layers, positional encoding, transformer encoded layers, and produces the final output using lm_head\n",
    "* mask generation: Both decoder and forward methods contain logic to generate a square casual mask if no source mask is provided. Mask ensures that the prediction for a position does not depend on the future tokens in the sequences, which is important for auto regressive nature of gpt models\n",
    "* Commented out decoder: A section of the code is commented out, suggesting an initial design where a transformer decoder layer was considered. However, the final implementation uses only encoder layers only, which is a common simplification for models focusing on language modeling and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a201b591-a5e9-47e7-bc0b-a8867628049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                emb_dim: int,\n",
    "                vocab_size: int,\n",
    "                num_head: int,\n",
    "                num_layers: int,\n",
    "                max_seq_len: 500,\n",
    "                dropout = 0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size,emb_dim)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(emb_dim = emb_dim,dropout = dropout)\n",
    "\n",
    "        print(f\"EMBEDDING DIMENSION: {emb_dim}\")\n",
    "\n",
    "        # Remaining layers are part of the TransformerDecoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model = emb_dim,\n",
    "                                              nhead = num_head,\n",
    "                                              dropout = dropout)\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer = encoder_layers,\n",
    "                                                        num_layers = num_layers)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size) # produce the final output, the final logits over the vocabulary\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim()>1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def create_mask(src,device = DEVICE):\n",
    "        src_seq_len = src.shape[0] # src_shape: [seq_len,batch_size,emb_dim]\n",
    "        src_mask = nn.Transformer.generate_square_subsequent_mask(src_seq_len)\n",
    "        src_padding_mask = (src ==PAD_IDX).transpose(0,1)\n",
    "        return src_mask ,src_padding_mask\n",
    "\n",
    "    def decoder(self,x,src_mask):\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        seq_len = x.size(0)\n",
    "\n",
    "\n",
    "        # Add positional arguments to the input embeddings\n",
    "\n",
    "        x = self.embed(x)*math.sqrt(self.emb_dim)\n",
    "\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        if src_mask is None:\n",
    "            \"Generate a square casual mask for the sequence. The masked positions are filled with -inf and the unmasked positions will be filled with 0\"\n",
    "\n",
    "            src_mask,src_padding_mask = create_mask(x)\n",
    "\n",
    "        output = self.transformer_encoder(x,src_mask)\n",
    "        logits = self.lm_head(output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def forward(self,x,src_mask = None, key_padding_mask = None):\n",
    "\n",
    "        print(f\"Forward input shape: {x.shape}\")\n",
    "\n",
    "        seq_len = x.size(0)\n",
    "\n",
    "        # add positional embeddings to the input embeddings\n",
    "\n",
    "        embedding = self.embed(x) * math.sqrt(self.emb_dim)\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        if src_mask is None:\n",
    "            src_mask, src_padding_mask= create_mask(x)\n",
    "            \n",
    "\n",
    "        output =self.transformer_encoder(x,src_mask,key_padding_mask)\n",
    "\n",
    "        x = self.lm_head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc55c4f-f4e1-4aac-973b-2fba1b4917f0",
   "metadata": {},
   "source": [
    "## Model Configaration and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd2c30-d420-42ae-abaa-9f27b491b011",
   "metadata": {},
   "source": [
    "* **`STEPS`**:\n",
    "  1) Create the tokens of the datasets, and vocabularies\n",
    "  2) Create the collate funcion; which will return `source` and `target`\n",
    "  3) create positional encodings (source)\n",
    "  4) create embeddings (source)\n",
    "  5) create mask\n",
    "  6) create transformer layers\n",
    "  7) create transformer encoder\n",
    "  8) pass the output of the transformer encoder throught the linear logit\n",
    "\n",
    "\n",
    "**`Configure and instantiate a custom gpt model with the following specification`**\n",
    "* ntokens: Its basically the `vocab_size`, total number of unique tokens in the vocabulary, which the model will use to represent the word\n",
    "* emsize: The size of each embedding vector. In this model, each word will be represented by a 200 dimensional vector.\n",
    "* n_players: the number of transformer encoder layers in the model. We are using two layers in this configuaration\n",
    "* n_head: the number of attention heads in the multi head attention mechanism. The model will use two attention heads.\n",
    "* dropout: A regularization technique which randomly select neurons are ignored during training to prevent overfitting.  Here, we set the dropout to 0.2\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b20ad03-7dbc-42e9-89a9-aec2b025dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING DIMENSION: 200\n"
     ]
    }
   ],
   "source": [
    "ntokens = len(vocab) \n",
    "emb_dim = 200\n",
    "n_layers = 2\n",
    "nhead = 2\n",
    "dropout = 0.2\n",
    "\n",
    "model =  CustomGPTModel(emb_dim = emb_dim,\n",
    "                       vocab_size=ntokens,\n",
    "                       num_head = nhead,\n",
    "                       num_layers = n_layers,\n",
    "                       max_seq_len=5000).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78936f17-68c2-4dde-8c3f-d624a366626c",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57bc60ff-d7c4-478b-a6cb-22790e64f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_prompt(prompt,block_size = BLOCK_SIZE):\n",
    "\n",
    "    \"\"\"take the blocksize and fit it for proper input\"\"\"\n",
    "    while prompt is None:\n",
    "        prompt = input(\"Sorry, prompt can be empty. Please enter a valid prompt: \\n\")\n",
    "\n",
    "    tokens = tokenizer(prompt)\n",
    "\n",
    "    number_of_tokens = len(tokens)\n",
    "\n",
    "    if number_of_tokens>block_size:\n",
    "        tokens = tokens[-block_size:] # taken into account the last tokens\n",
    "\n",
    "    prompt_indices = vocab(tokens)\n",
    "\n",
    "    prompt_encoded = torch.tensor(prompt_indices, dtype = torch.int64).reshape(-1,1)\n",
    "    print(f\"The shape of the prompt tensor: {prompt_encoded.shape}\")\n",
    "\n",
    "    return prompt_encoded\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "742731ea-b8cc-42a8-8088-ed94ef22f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sorry, prompt can be empty. Please enter a valid prompt: \n",
      " The sky is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the prompt tensor: torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "prompt_name = encode_prompt(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b8941-0831-46c7-98b8-bc052163fcff",
   "metadata": {},
   "source": [
    "## Output (Logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca29aadc-9cb0-4848-ab67-3a1d79fc6afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 68813])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model.decoder(prompt_name,src_mask = None)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a272ba14-0ac6-4cdf-9deb-d32f886942a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68813"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7945ca5-b15d-4b8c-b21d-d07f31927fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape of the logit: torch.Size([1, 3, 68813])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 68813])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits.transpose(0,1)\n",
    "print(f\"The new shape of the logit: {logits.shape}\")\n",
    "\n",
    "logit_prediction = logits[:,-1] # take all the rows but the last column\n",
    "logit_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27f7a000-31b8-4a81-8db2-f37cc456e419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35805], device='mps:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,next_word_index = torch.max(logit_prediction, dim = 1)\n",
    "next_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2793cf21-ac66-47f7-998a-11d734b0f307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'valcos'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_word = idx_to_text(next_word_index)\n",
    "\n",
    "predicted_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9341c-d500-44da-88c4-c42ae1df46ef",
   "metadata": {},
   "source": [
    "## Autoregressive Text Generation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f51197af-26fa-4038-8d22-55ab91b96a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Sequence Shape:torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "prompt = 'mother is the best warrior'\n",
    "\n",
    "start_seq = encode_prompt(prompt).to(DEVICE)\n",
    "\n",
    "print(f\"Start Sequence Shape:{start_seq.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f091ffcb-d594-450a-acb7-dc6fe0dde252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Shape of logits at step 0: torch.Size([1, 5, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining']\n",
      " \n",
      "Shape of logits at step 1: torch.Size([1, 6, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational']\n",
      " \n",
      "Shape of logits at step 2: torch.Size([1, 7, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic']\n",
      " \n",
      "Shape of logits at step 3: torch.Size([1, 8, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic', 'sticked']\n",
      " \n",
      "Shape of logits at step 4: torch.Size([1, 9, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic', 'sticked', 'wholeheartedly']\n",
      " \n",
      "Shape of logits at step 5: torch.Size([1, 10, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic', 'sticked', 'wholeheartedly', 'klane']\n",
      " \n",
      "Shape of logits at step 6: torch.Size([1, 11, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic', 'sticked', 'wholeheartedly', 'klane', 'mainstream-aspiring']\n",
      " \n",
      "Shape of logits at step 7: torch.Size([1, 12, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic', 'sticked', 'wholeheartedly', 'klane', 'mainstream-aspiring', 'warranted']\n",
      " \n",
      "Shape of logits at step 8: torch.Size([1, 13, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic', 'sticked', 'wholeheartedly', 'klane', 'mainstream-aspiring', 'warranted', 'geeze']\n",
      " \n",
      "Shape of logits at step 9: torch.Size([1, 14, 68813])\n",
      "Probable Line: ['mother', 'is', 'the', 'best', 'warrior', 'raining', 'nondenominational', 'hispanic', 'sticked', 'wholeheartedly', 'klane', 'mainstream-aspiring', 'warranted', 'geeze', 'approachable']\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens = 10 # the number of words you want to show as the output\n",
    "\n",
    "for i in range(max_new_tokens):\n",
    "\n",
    "    logits = model.decoder(start_seq,src_mask = None)\n",
    "\n",
    "    logits = logits.transpose(0,1) # interchange the first two dimensions of the matrix\n",
    "\n",
    "    print(\" \")\n",
    "    print(f\"Shape of logits at step {i}: {logits.shape}\")\n",
    "    \n",
    "    logit_prediction = logits[:,-1]\n",
    "\n",
    "    next_token_encoded = torch.argmax(logit_prediction,dim = 1).reshape(-1,1)\n",
    "\n",
    "\n",
    "    start_seq = torch.cat((start_seq,next_token_encoded),dim = 0).to(DEVICE)\n",
    "    print(f\"Probable Line: {[idx_to_text(j) for j in start_seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c824b69a-b26f-4151-bd86-103b604582e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto generation function\n",
    "\n",
    "def auto_generate(model,prompt = None, max_new_tokens = 500,block_size = BLOCK_SIZE,vocab = vocab, tokenizer = tokenizer):\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    \"\"\"architecture: prompt will converted to tensor eventually\"\"\"\n",
    "\n",
    "    encoded_prompt = encode_prompt(prompt).to(DEVICE)\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        print(f\"encoded prompt shape: {encoded_prompt.shape}\")\n",
    "\n",
    "        # decode the encoded prompt using the model's decoder\n",
    "\n",
    "        logits = model(encoded_prompt,src_mask = None, key_padding_mask = None)\n",
    "\n",
    "        print(f\"Shape of the logits {logits.shape}\")\n",
    "\n",
    "        logits_reshaped = logits.transpose(0,1) # Shape before [seq_len,batch_size,vocab_size] --> shape now[batch_size,seq_len,vocab_size]\n",
    "\n",
    "        logits_prediction = logits_reshaped[:,-1]\n",
    "\n",
    "        predicted_logit = torch.argmax(logits_prediction, dim =-1).reshape(-1,1)\n",
    "\n",
    "        # if the next token is the end of sequence(EOS) token, stop generation\n",
    "        \n",
    "        if predicted_logit.item() == EOS_IDX:\n",
    "            break\n",
    "\n",
    "        # Append the next token to the prompt encoded and keep only the last block size tokens\n",
    "        prompt_encoded = torch.cat((prompt,predicted_logit),dim = 0)[-block_size:]\n",
    "\n",
    "\n",
    "        #convert the token index to a token string\n",
    "    return [idx_to_text(tokens) for tokens in prompt_encoded]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e2b7f0d-da26-48c1-abec-79ded3b99d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the prompt tensor: torch.Size([8, 1])\n",
      "encoded prompt shape: torch.Size([8, 1])\n",
      "Forward input shape: torch.Size([8, 1])\n",
      "Shape of the logits torch.Size([8, 8, 68813])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 8 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m auto_generate_text \u001b[38;5;241m=\u001b[39m auto_generate(model \u001b[38;5;241m=\u001b[39m model, prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md love to take the pictures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[90], line 30\u001b[0m, in \u001b[0;36mauto_generate\u001b[0;34m(model, prompt, max_new_tokens, block_size, vocab, tokenizer)\u001b[0m\n\u001b[1;32m     26\u001b[0m predicted_logit \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits_prediction, dim \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# if the next token is the end of sequence(EOS) token, stop generation\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predicted_logit\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m EOS_IDX:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Append the next token to the prompt encoded and keep only the last block size tokens\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 8 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "auto_generate_text = auto_generate(model = model, prompt = \"I'd love to take the pictures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5bb0c2c-100b-4f99-a551-077598d3b221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the prompt tensor: torch.Size([8, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  13],\n",
       "         [   8],\n",
       "         [ 216],\n",
       "         [ 174],\n",
       "         [  10],\n",
       "         [ 205],\n",
       "         [   4],\n",
       "         [1509]]),\n",
       " torch.Size([8, 1]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I'd love to take the pictures\"\n",
    "encoded_prompt = encode_prompt(prompt)\n",
    "encoded_prompt,encoded_prompt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d211fc28-4bf1-4a72-953b-290eb4663a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 68813])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e027933-916c-4580-ab35-585ae41a8f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a73204ff-2181-4fe9-bb0b-54636edf02d5",
   "metadata": {},
   "source": [
    "## Again start from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "83b4a6a0-b4ae-4060-9c01-6ecbd04e249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68813\n"
     ]
    }
   ],
   "source": [
    "# get the dataset\n",
    "from torchtext.datasets import IMDB\n",
    "train_iter, test_iter = IMDB()\n",
    "\n",
    "# set the vocab and tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _,text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "UNK_IDX,PAD_IDX,EOS_IDX = 0,1,2\n",
    "special_symbols = ['<unk>','<pad>',\"<|endoftext|>\"]\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter),specials = special_symbols,special_first=True)\n",
    "print(len(vocab))\n",
    "\n",
    "\n",
    "def get_sample2(context_size, text_tokens):\n",
    "\n",
    "    src_seq,trg_seq = [],[]\n",
    "\n",
    "    if len(text_tokens)>context_size:\n",
    "        start_ceiling = len(text_tokens)-context_size\n",
    "        start = torch.randint(0,start_ceiling,size=(1,))\n",
    "        end = start+context_size\n",
    "        src_seq = text_tokens[start:end]\n",
    "        trg_seq = text_tokens[start+1:end+1]\n",
    "\n",
    "    elif context_size> len(text_tokens):\n",
    "        start = torch.randint(0,len(text_tokens),size = (1,))\n",
    "\n",
    "        end = start+context_size\n",
    "\n",
    "        src_seq = text_tokens[start:end]\n",
    "        end_seq = text_tokens[start+1:end]\n",
    "\n",
    "        \n",
    "        end_seq.append('')\n",
    "\n",
    "\n",
    "    return src_seq,trg_seq\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1c857240-6187-450c-99ff-1614a189b3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n",
      "\n",
      "source sequence: ['s', 'not', 'shot', 'like', 'some', 'cheaply', 'made', 'porno', '.', 'while', 'my', 'countrymen', 'mind', 'find', 'it', 'shocking', ',', 'in', 'reality', 'sex']\n",
      "\n",
      "Source tensors: tensor([   17,    30,   308,    43,    55,  4965,    96,  2755,     3,   155,\n",
      "           72, 24085,   369,   196,    12,  1582,     5,    14,   788,   338])\n",
      "\n",
      "target sequence: ['not', 'shot', 'like', 'some', 'cheaply', 'made', 'porno', '.', 'while', 'my', 'countrymen', 'mind', 'find', 'it', 'shocking', ',', 'in', 'reality', 'sex', 'and']\n",
      "\n",
      "target tensors: tensor([   30,   308,    43,    55,  4965,    96,  2755,     3,   155,    72,\n",
      "        24085,   369,   196,    12,  1582,     5,    14,   788,   338,     7])\n",
      "\n",
      "Sample: 1\n",
      "\n",
      "source sequence: ['swede', 'thought', 'about', 'certain', 'political', 'issues', 'such', 'as', 'the', 'vietnam', 'war', 'and', 'race', 'issues', 'in', 'the', 'united', 'states', '.', 'in']\n",
      "\n",
      "Source tensors: tensor([22750,   207,    52,   907,  1171,  1462,   152,    23,     4,  2430,\n",
      "          458,     7,  1610,  1462,    14,     4,  2671,  1768,     3,    14])\n",
      "\n",
      "target sequence: ['thought', 'about', 'certain', 'political', 'issues', 'such', 'as', 'the', 'vietnam', 'war', 'and', 'race', 'issues', 'in', 'the', 'united', 'states', '.', 'in', 'between']\n",
      "\n",
      "target tensors: tensor([ 207,   52,  907, 1171, 1462,  152,   23,    4, 2430,  458,    7, 1610,\n",
      "        1462,   14,    4, 2671, 1768,    3,   14,  259])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_batch,tgr_batch = [],[]\n",
    "\n",
    "BATCH_SIZE  = 2\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    _,text = next(iter(train_iter))\n",
    "    text_tokens = tokenizer(text)\n",
    "\n",
    "    src_seq,trg_seq = get_sample2(context_size=20,text_tokens=text_tokens)\n",
    "\n",
    "    src_indices,trg_indices = vocab(src_seq),vocab(trg_seq)\n",
    "\n",
    "    src_tensors, trg_tensors = torch.tensor(src_indices,dtype = torch.int64),torch.tensor(trg_indices,dtype = torch.int64)\n",
    "\n",
    "    \n",
    "\n",
    "    src_batch.append(src_seq)\n",
    "    trg_batch.append(trg_seq)\n",
    "\n",
    "    print(f\"Sample: {i}\\n\")\n",
    "    print(f\"source sequence: {src_seq}\\n\")\n",
    "    print(f\"Source tensors: {src_tensors}\\n\")\n",
    "    print(f\"target sequence: {trg_seq}\\n\")\n",
    "    print(f\"target tensors: {trg_tensors}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c30483bc-c5af-4d33-8758-eac3aac0e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 30\n",
    "\n",
    "def collate_batch(batch):\n",
    "    src_batch,trg_batch = [],[]\n",
    "\n",
    "    for _,text in batch:\n",
    "        src_seq,trg_seq = get_sample2(BLOCK_SIZE,tokenizer(text))\n",
    "        src_sequence = vocab(src_seq)\n",
    "        trg_sequence = vocab(trg_seq)\n",
    "\n",
    "        src_sequence = torch.tensor(src_sequence,dtype = torch.int64)\n",
    "        trg_sequence = torch.tensor(tgr_sequence,dtype = torch.int64)\n",
    "\n",
    "        src_batch.append(src_sequence)\n",
    "        tgr_batch.append(trg_sequence)\n",
    "\n",
    "\n",
    "    src_batch = pad_sequence(src_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "    trg_batch = pad_sequence(trg_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "\n",
    "\n",
    "    return src_batch.to(DEVICE),trg_batch.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cbcbef00-6aeb-4984-a00b-37ed5e7b77ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label,data = next(iter(train_iter))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eed167b5-504f-4275-bc6f-84881ac474fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    _,text = next(iter(train_iter))\n",
    "\n",
    "    output = tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2ab8f2b-b117-40f6-b491-24b071a8100b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 317)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output),len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "85d32a4e-bd8c-438d-9a13-401dffc70cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d48bd5f4-eb65-4d7a-b216-8c59eb19c1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'rented',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'from',\n",
       " 'my',\n",
       " 'video',\n",
       " 'store',\n",
       " 'because']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_of_tokens[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3222823a-52eb-4c5d-ad21-1d49735ff110",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_batch,trg_batch = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0694578-8530-4a5d-b2c6-1cb47916ba1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['i',\n",
       "   'rented',\n",
       "   'i',\n",
       "   'am',\n",
       "   'curious-yellow',\n",
       "   'from',\n",
       "   'my',\n",
       "   'video',\n",
       "   'store',\n",
       "   'because',\n",
       "   'of',\n",
       "   'all',\n",
       "   'the',\n",
       "   'controversy',\n",
       "   'that',\n",
       "   'surrounded',\n",
       "   'it',\n",
       "   'when',\n",
       "   'it',\n",
       "   'was',\n",
       "   'first',\n",
       "   'released',\n",
       "   'in',\n",
       "   '1967',\n",
       "   '.',\n",
       "   'i',\n",
       "   'also',\n",
       "   'heard',\n",
       "   'that',\n",
       "   'at',\n",
       "   'first',\n",
       "   'it',\n",
       "   'was',\n",
       "   'seized',\n",
       "   'by',\n",
       "   'u',\n",
       "   '.',\n",
       "   's',\n",
       "   '.',\n",
       "   'customs',\n",
       "   'if',\n",
       "   'it',\n",
       "   'ever',\n",
       "   'tried',\n",
       "   'to',\n",
       "   'enter',\n",
       "   'this',\n",
       "   'country',\n",
       "   ',',\n",
       "   'therefore',\n",
       "   'being',\n",
       "   'a',\n",
       "   'fan',\n",
       "   'of',\n",
       "   'films',\n",
       "   'considered',\n",
       "   'controversial',\n",
       "   'i',\n",
       "   'really',\n",
       "   'had',\n",
       "   'to',\n",
       "   'see',\n",
       "   'this',\n",
       "   'for',\n",
       "   'myself',\n",
       "   '.',\n",
       "   'the',\n",
       "   'plot',\n",
       "   'is',\n",
       "   'centered',\n",
       "   'around',\n",
       "   'a',\n",
       "   'young',\n",
       "   'swedish',\n",
       "   'drama',\n",
       "   'student',\n",
       "   'named',\n",
       "   'lena',\n",
       "   'who',\n",
       "   'wants',\n",
       "   'to',\n",
       "   'learn',\n",
       "   'everything',\n",
       "   'she',\n",
       "   'can',\n",
       "   'about',\n",
       "   'life',\n",
       "   '.',\n",
       "   'in',\n",
       "   'particular',\n",
       "   'she',\n",
       "   'wants',\n",
       "   'to',\n",
       "   'focus',\n",
       "   'her',\n",
       "   'attentions',\n",
       "   'to',\n",
       "   'making',\n",
       "   'some',\n",
       "   'sort',\n",
       "   'of',\n",
       "   'documentary',\n",
       "   'on',\n",
       "   'what',\n",
       "   'the',\n",
       "   'average',\n",
       "   'swede',\n",
       "   'thought',\n",
       "   'about',\n",
       "   'certain',\n",
       "   'political',\n",
       "   'issues',\n",
       "   'such',\n",
       "   'as',\n",
       "   'the',\n",
       "   'vietnam',\n",
       "   'war',\n",
       "   'and',\n",
       "   'race',\n",
       "   'issues',\n",
       "   'in',\n",
       "   'the',\n",
       "   'united',\n",
       "   'states',\n",
       "   '.',\n",
       "   'in',\n",
       "   'between',\n",
       "   'asking',\n",
       "   'politicians',\n",
       "   'and',\n",
       "   'ordinary',\n",
       "   'denizens',\n",
       "   'of',\n",
       "   'stockholm',\n",
       "   'about',\n",
       "   'their',\n",
       "   'opinions',\n",
       "   'on',\n",
       "   'politics',\n",
       "   ',',\n",
       "   'she',\n",
       "   'has',\n",
       "   'sex',\n",
       "   'with',\n",
       "   'her',\n",
       "   'drama',\n",
       "   'teacher',\n",
       "   ',',\n",
       "   'classmates',\n",
       "   ',',\n",
       "   'and',\n",
       "   'married',\n",
       "   'men',\n",
       "   '.',\n",
       "   'what',\n",
       "   'kills',\n",
       "   'me',\n",
       "   'about',\n",
       "   'i',\n",
       "   'am',\n",
       "   'curious-yellow',\n",
       "   'is',\n",
       "   'that',\n",
       "   '40',\n",
       "   'years',\n",
       "   'ago',\n",
       "   ',',\n",
       "   'this',\n",
       "   'was',\n",
       "   'considered',\n",
       "   'pornographic',\n",
       "   '.',\n",
       "   'really',\n",
       "   ',',\n",
       "   'the',\n",
       "   'sex',\n",
       "   'and',\n",
       "   'nudity',\n",
       "   'scenes',\n",
       "   'are',\n",
       "   'few',\n",
       "   'and',\n",
       "   'far',\n",
       "   'between',\n",
       "   ',',\n",
       "   'even',\n",
       "   'then',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'not',\n",
       "   'shot',\n",
       "   'like',\n",
       "   'some',\n",
       "   'cheaply',\n",
       "   'made',\n",
       "   'porno',\n",
       "   '.',\n",
       "   'while',\n",
       "   'my',\n",
       "   'countrymen',\n",
       "   'mind',\n",
       "   'find',\n",
       "   'it',\n",
       "   'shocking',\n",
       "   ',',\n",
       "   'in',\n",
       "   'reality',\n",
       "   'sex',\n",
       "   'and',\n",
       "   'nudity',\n",
       "   'are',\n",
       "   'a',\n",
       "   'major',\n",
       "   'staple',\n",
       "   'in',\n",
       "   'swedish',\n",
       "   'cinema',\n",
       "   '.',\n",
       "   'even',\n",
       "   'ingmar',\n",
       "   'bergman',\n",
       "   ',',\n",
       "   'arguably',\n",
       "   'their',\n",
       "   'answer',\n",
       "   'to',\n",
       "   'good',\n",
       "   'old',\n",
       "   'boy',\n",
       "   'john',\n",
       "   'ford',\n",
       "   ',',\n",
       "   'had',\n",
       "   'sex',\n",
       "   'scenes',\n",
       "   'in',\n",
       "   'his',\n",
       "   'films',\n",
       "   '.',\n",
       "   'i',\n",
       "   'do',\n",
       "   'commend',\n",
       "   'the',\n",
       "   'filmmakers',\n",
       "   'for',\n",
       "   'the',\n",
       "   'fact',\n",
       "   'that',\n",
       "   'any',\n",
       "   'sex',\n",
       "   'shown',\n",
       "   'in',\n",
       "   'the',\n",
       "   'film',\n",
       "   'is',\n",
       "   'shown',\n",
       "   'for',\n",
       "   'artistic',\n",
       "   'purposes',\n",
       "   'rather',\n",
       "   'than',\n",
       "   'just',\n",
       "   'to',\n",
       "   'shock',\n",
       "   'people',\n",
       "   'and',\n",
       "   'make',\n",
       "   'money',\n",
       "   'to',\n",
       "   'be',\n",
       "   'shown',\n",
       "   'in',\n",
       "   'pornographic',\n",
       "   'theaters',\n",
       "   'in',\n",
       "   'america',\n",
       "   '.',\n",
       "   'i',\n",
       "   'am',\n",
       "   'curious-yellow',\n",
       "   'is',\n",
       "   'a',\n",
       "   'good',\n",
       "   'film',\n",
       "   'for',\n",
       "   'anyone',\n",
       "   'wanting',\n",
       "   'to',\n",
       "   'study',\n",
       "   'the',\n",
       "   'meat',\n",
       "   'and',\n",
       "   'potatoes',\n",
       "   '(',\n",
       "   'no',\n",
       "   'pun',\n",
       "   'intended',\n",
       "   ')',\n",
       "   'of',\n",
       "   'swedish',\n",
       "   'cinema',\n",
       "   '.',\n",
       "   'but',\n",
       "   'really',\n",
       "   ',',\n",
       "   'this',\n",
       "   'film',\n",
       "   'doesn',\n",
       "   \"'\",\n",
       "   't',\n",
       "   'have',\n",
       "   'much',\n",
       "   'of',\n",
       "   'a',\n",
       "   'plot',\n",
       "   '.']],\n",
       " [])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046981a3-ca52-4e6f-8194-a46f1a027947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
