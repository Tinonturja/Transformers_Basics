{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d91c21-c2a7-4df5-b19e-77ea6537aacb",
   "metadata": {},
   "source": [
    "## BERT's BASICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56029f77-92b9-4867-9e49-ab9da569ba04",
   "metadata": {},
   "source": [
    "BERT's architecture allows for fine tuning specific tasks like:\n",
    "* Text summarization\n",
    "* Question Answering\n",
    "* Sentiment Analysis\n",
    "\n",
    "Uses only `encoder_only` architecture to process entire sequences of text simultaneously\n",
    "`MLM` involves randomly masking some of the input tokens and training BERT to predict the original masked tones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8744ce8-0ab4-45ac-a153-504c3132caeb",
   "metadata": {},
   "source": [
    "For prediction:\n",
    "\n",
    "    * Encoder outputs a set of contextual embeddings\n",
    "    * Contextual embeddings are passed through another layer and converted into a set of logits.\n",
    "    * Masked word is identified by selecting the word corresponding to the index with the highest logit value. \n",
    "\n",
    "Encoder models have access to the entire sequence.\n",
    "\n",
    "The training method is `bidirectional`\n",
    "\n",
    "    * It enables the model to understand the context from both sides of any given word in a sentence.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d24efd-888f-4b51-8499-42d0e8a2e4f7",
   "metadata": {},
   "source": [
    "### Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb2d094-c4f8-4f6d-a1e2-a7ef3129368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "\n",
    "# New\n",
    "from torch.nn import Transformer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf768b5-95d6-4272-944c-cc3c915c453d",
   "metadata": {},
   "source": [
    "### Pretraining objectives\n",
    "\n",
    "Pretraining objectives are crucial components of the pretraining process for transformers. These objectives define the tasks that the model is trained on during the pretraining phase, allowing it to learn meaningful contextual representations of language. Two commonly used pretraining objectives are masked language modeling (MLM) and next sentence prediction (NSP).\n",
    "\n",
    "1. Masked Language Modeling (MLM):\n",
    "   Masked language modeling involves randomly masking some words in a sentence and training the model to predict the masked words based on the context provided by the surrounding words(i.e., words that appear either before or after the masked word). The objective is to enable the model to learn contextual understanding and fill in missing information.\n",
    "\n",
    "   Here's how MLM works:\n",
    "   - Given an input sentence, a certain percentage of the words are randomly chosen and replaced with a special [MASK] token.\n",
    "   - The model's task is to predict the original words that were masked, given the context of the surrounding words.\n",
    "   - During training, the model learns to understand the relationship between the masked words and the rest of the sentence, effectively capturing the contextual information.\n",
    "\n",
    "2. Next Sentence Prediction (NSP):\n",
    "   Next sentence prediction involves training the model to predict whether two sentences are consecutive in the original text or randomly chosen from the corpus. This objective helps the model learn sentence-level relationships and understand the coherence between sentences.\n",
    "\n",
    "   Here's how NSP works:\n",
    "   - Given a pair of sentences, the model is trained to predict whether the second sentence follows the first sentence in the original text or if it is randomly selected from the corpus.\n",
    "   - The model learns to capture the relationships between sentences and understand the flow of information in the text.\n",
    "\n",
    "   NSP is particularly useful for tasks that involve understanding the relationship between multiple sentences, such as question answering or document classification. By training the model to predict the coherence of sentence pairs, it learns to capture the semantic connections between them.\n",
    "\n",
    "It's important to note that different pretrained models may use variations or combinations of these objectives, depending on the specific architecture and training setup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b685fcfa-b11a-41f3-aa1a-d41c497a02f0",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a005c6-33bc-43ba-a8eb-10a45eda4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-31 11:50:54--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/bZaoQD52DcMpE7-kxwAG8A.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
      "connected. to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88958506 (85M) [application/zip]\n",
      "Saving to: ‘BERT_dataset.zip’\n",
      "\n",
      "BERT_dataset.zip    100%[===================>]  84.84M  2.23MB/s    in 41s     \n",
      "\n",
      "2025-07-31 11:51:42 (2.06 MB/s) - ‘BERT_dataset.zip’ saved [88958506/88958506]\n",
      "\n",
      "Archive:  BERT_dataset.zip\n",
      "   creating: /Users/tinonturjamajumder/Generative AI Language Modelling with Transformers_3/bert_dataset\n",
      "  inflating: bert_dataset/.DS_Store  \n",
      "  inflating: bert_dataset/bert_train_data.csv  \n",
      "  inflating: bert_dataset/bert_test_data_sampled.csv  \n",
      "  inflating: bert_dataset/bert_test_data.csv  \n",
      "  inflating: bert_dataset/bert_train_data_sampled.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget -O BERT_dataset.zip https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/bZaoQD52DcMpE7-kxwAG8A.zip\n",
    "!unzip BERT_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22a77fb-1328-4e52-9fce-4c636e8e618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTCSVDataset(Dataset):\n",
    "\n",
    "    def __init__(self,filename):\n",
    "        self.data = pd.read_csv(filename)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        try:\n",
    "            bert_input = torch.tensor(json.loads(row[\"BERT Input\"]),dtype = torch.long)\n",
    "            bert_label = torch.tensor(json.loads(row['BERT Label']),dtype = torch.long)\n",
    "            segment_label = torch.tensor([int(x) for x in row['Segment Label'].split(',')],dtype = torch.long)\n",
    "            is_next = torch.tensor(row['Is Next'],dtype = torch.long)\n",
    "            original_text = row['Original Text']\n",
    "\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            \n",
    "            print(f\"Error decoding JSON for row {idx}: {e}\")\n",
    "            print(f\"BERT Input: {row['BERT Input']}'\")\n",
    "            print(f\"BERT Label: {row[\"BERT Label\"]}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "        encoded_input = self.tokenizer.encode_plus(\n",
    "            original_text,\n",
    "            add_special_tokens = True,\n",
    "            max_length = 512,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoded_input['input_ids'].squeeze()\n",
    "        attention_mask = encoded_input['attention_mask'].squeeze()\n",
    "\n",
    "        return(bert_input,bert_label,segment_label,is_next,input_ids,attention_mask,original_text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "466a92d9-19a7-40e0-8097-3428635a9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "def collate_batch(batch):\n",
    "    bert_inputs_batch,bert_label_batch,bert_segment_batch,is_next_batch,input_ids_batch,attention_mask_batch,original_text_batch =  [], [], [], [],[],[],[]\n",
    "\n",
    "\n",
    "    for bert_inputs,bert_label,bert_segment,is_next,input_ids,attention_mask,original_text in batch:\n",
    "\n",
    "        bert_inputs_batch.append(torch.tensor(bert_inputs,dtype = torch.long))\n",
    "        bert_label_batch.append(torch.tensor(bert_label,dtype = torch.long))\n",
    "        bert_segment_batch.append(torch.tensor(bert_segment,dtype= torch.long))\n",
    "        is_next_batch.append(is_next)\n",
    "        input_ids_batch.append(input_ids)\n",
    "        attention_mask_batch.append(attention_mask)\n",
    "        original_text_batch.append(original_text)\n",
    "        \n",
    "\n",
    "    # pad the sequences in the batch\n",
    "    bert_inputs_final = pad_sequence(bert_inputs_batch,padding_value = PAD_IDX,batch_first = False)\n",
    "    bert_labels_final = pad_sequence(bert_label_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "    segments_label_final = pad_sequence(bert_segment_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "    is_nexts_final = torch.tensor(is_next_batch,dtype = torch.long)\n",
    "\n",
    "    return bert_inputs_final, bert_labels_final, segments_label_final,is_nexts_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "082499b1-b015-476d-a300-6ebb1d67a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "train_dataset_path = 'bert_dataset/bert_train_data.csv'\n",
    "test_dataset_path = 'bert_dataset/bert_test_data.csv'\n",
    "\n",
    "\n",
    "train_dataset = BERTCSVDataset(train_dataset_path)\n",
    "test_dataset = BERTCSVDataset(test_dataset_path)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             shuffle= True,\n",
    "                             collate_fn = collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                             shuffle= True,\n",
    "                             collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a0ac165-8e6b-4b8f-ae0c-05a08828cb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    1,    21,    22,     5,  2263,    18,  7236,   928,  1003,     3,\n",
       "            44,     3, 12033,     3,    18,   220,    12,    30,   294,     6,\n",
       "             2,     0,     0,     0,     0,    15,   201,     7,    29,  1192,\n",
       "           382,    12,    30,     3,   664, 11648,    15,    44,     3,    26,\n",
       "            15,   239,     3,    10,  1542,    51,  3748, 16246,     6,     2]),\n",
       " tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,    13,\n",
       "             0,  7876,     0, 92127,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,    77,     0,     0,     0,     0,   328,     0,\n",
       "             0,     0,  4852,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2]),\n",
       " tensor(0),\n",
       " tensor([  101,  1000,  1045,  2572,  8025,  1024,  3756,  1000,  2003,  1037,\n",
       "         15544, 19307,  1998,  3653,  6528, 20771, 19986,  8632,  1012,  2009,\n",
       "          2987,  1005,  1056,  3043,  2054,  2028,  1005,  1055,  2576,  5328,\n",
       "          2024,  2138,  2023,  2143,  2064,  6684,  2022,  2579,  5667,  2006,\n",
       "          2151,  2504,  1012,  2004,  2005,  1996,  4366,  2008, 19124,  3287,\n",
       "         16371, 25469,  2003,  2019,  6882, 13316,  1011,  2459,  1010,  2008,\n",
       "          3475,  1005,  1056,  2995,  1012,  1045,  1005,  2310,  2464,  1054,\n",
       "          1011,  6758,  3152,  2007,  3287, 16371, 25469,  1012,  4379,  1010,\n",
       "          2027,  2069,  3749,  2070, 25085,  5328,  1010,  2021,  2073,  2024,\n",
       "          1996,  1054,  1011,  6758,  3152,  2007, 21226, 24728, 22144,  2015,\n",
       "          1998, 20916,  4691,  6845,  2401,  1029,  7880,  1010,  2138,  2027,\n",
       "          2123,  1005,  1056,  4839,  1012,  1996,  2168,  3632,  2005,  2216,\n",
       "         10231,  7685,  5830,  3065,  1024,  8040,  7317,  5063,  2015, 11820,\n",
       "          1999,  1996,  9478,  2021,  2025,  1037, 17962, 21239,  1999,  4356,\n",
       "          1012,  1998,  2216,  3653,  6528, 20771, 10271,  5691,  2066,  1996,\n",
       "          2829, 16291,  1010,  1999,  2029,  2057,  1005,  2128,  5845,  2000,\n",
       "          1996,  2609,  1997,  6320, 25624,  1005,  1055, 17061,  3779,  1010,\n",
       "          2021,  2025,  1037,  7637,  1997,  5061,  5710,  2006,  9318,  7367,\n",
       "          5737, 19393,  1012,  2077,  6933,  1006,  2030, 20242,  1007,  1000,\n",
       "          3313,  1011,  3115,  1000,  1999,  5609,  1997, 16371, 25469,  1010,\n",
       "          1996, 10597, 27885,  5809,  2063,  2323,  2202,  2046,  4070,  2028,\n",
       "         14477,  6767,  8524,  6321,  5793, 28141,  4489,  2090,  2273,  1998,\n",
       "          2308,  1024,  2045,  2024,  2053,  8991, 18400,  2015,  2006,  4653,\n",
       "          2043, 19910,  3544, 15287,  1010,  1998,  1996,  2168,  3685,  2022,\n",
       "          2056,  2005,  1037,  2158,  1012,  1999,  2755,  1010,  2017,  3227,\n",
       "          2180,  1005,  1056,  2156,  2931,  8991, 18400,  2015,  1999,  2019,\n",
       "          2137,  2143,  1999,  2505,  2460,  1997, 22555,  2030, 13216, 14253,\n",
       "          2050,  1012,  2023,  6884,  3313,  1011,  3115,  2003,  2625,  1037,\n",
       "          3313,  3115,  2084,  2019,  4914,  2135,  2139, 24128,  3754,  2000,\n",
       "          2272,  2000,  3408, 20547,  2007,  1996, 19008,  1997,  2308,  1005,\n",
       "          1055,  4230,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample dataset\n",
    "train_dataset = iter(train_dataset)\n",
    "one_sample = next(train_dataset)\n",
    "two_sample = next(train_dataset)\n",
    "one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b7095cf-27c2-4483-8db1-8d2abefc2819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert_input_shape:torch.Size([40])\n",
      "Bert_label_shape:torch.Size([40])\n",
      "Segment_label_shape:torch.Size([40])\n",
      "is_next_shape:torch.Size([])\n",
      "input_ids_shape:torch.Size([512])\n",
      "Attention_mask_shape:torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the sample of a dataset\n",
    "print(f\"Bert_input_shape:{one_sample[0].shape}\")\n",
    "print(f\"Bert_label_shape:{one_sample[1].shape}\")\n",
    "print(f\"Segment_label_shape:{one_sample[2].shape}\")\n",
    "print(f\"is_next_shape:{one_sample[3].shape}\")\n",
    "print(f\"input_ids_shape:{one_sample[4].shape}\")\n",
    "print(f\"Attention_mask_shape:{one_sample[5].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65ddd7b2-aa30-47ed-aec2-5443c03b271e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a77a0f3a-873b-48db-8170-1537302faa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,     1],\n",
       "         [   16,  4983],\n",
       "         [  448,     3],\n",
       "         [   42,     5],\n",
       "         [    3, 22813],\n",
       "         [   99,     7],\n",
       "         [   83,     5],\n",
       "         [    7,  1405],\n",
       "         [  199, 13232],\n",
       "         [    7,     7],\n",
       "         [   21,     5],\n",
       "         [   33, 20257],\n",
       "         [   20,     8],\n",
       "         [    3,  1640],\n",
       "         [ 7561,   479],\n",
       "         [   31,     7],\n",
       "         [   38,    15],\n",
       "         [ 4038,     3],\n",
       "         [   43,   137],\n",
       "         [    9,  1494],\n",
       "         [  654,     3],\n",
       "         [ 2918,     2],\n",
       "         [   72,    16],\n",
       "         [ 6708,   223],\n",
       "         [30610,     3],\n",
       "         [    5,   350],\n",
       "         [89789,    31],\n",
       "         [    7,    67],\n",
       "         [43331,  3279],\n",
       "         [   99,    15],\n",
       "         [    8,  4149],\n",
       "         [   35,   146],\n",
       "         [    3,     3],\n",
       "         [    6,    20],\n",
       "         [    2,   252],\n",
       "         [   16,    31],\n",
       "         [   78,  2967],\n",
       "         [ 7137,     6],\n",
       "         [12571,     2],\n",
       "         [    3,     0],\n",
       "         [   97,     0],\n",
       "         [ 2881,     0],\n",
       "         [   10,     0],\n",
       "         [   17,     0],\n",
       "         [   26,     0],\n",
       "         [  134,     0],\n",
       "         [  242,     0],\n",
       "         [    3,     0],\n",
       "         [   20,     0],\n",
       "         [  353,     0],\n",
       "         [   11,     0],\n",
       "         [   81,     0],\n",
       "         [   31,     0],\n",
       "         [  297,     0],\n",
       "         [   41,     0],\n",
       "         [    3,     0],\n",
       "         [    6,     0],\n",
       "         [    2,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0]]),\n",
       " tensor([[    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     7],\n",
       "         [    0,     0],\n",
       "         [ 1520,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    7,     7],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [11276,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [ 4038,   421],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     6],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,   223],\n",
       "         [    0,  8039],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,  4149],\n",
       "         [    0,     0],\n",
       "         [35240,    16],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    5,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [   14,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [  297,     0],\n",
       "         [    0,     0],\n",
       "         [  959,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0],\n",
       "         [    0,     0]]),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [2, 2],\n",
       "         [2, 2],\n",
       "         [2, 2],\n",
       "         [2, 2],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [2, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]),\n",
       " tensor([0, 0]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_sample_dataloader = next(iter(train_dataloader))\n",
    "one_sample_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8b8d7-e02f-45c1-ae7d-5af8f1629e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a628f51-9702-4bce-92f9-2ffdf132a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 10\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self,vocab_size,emb_dim, dropout =0.1,train = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size,emb_dim)\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def forward(self,tokens):\n",
    "        return self.embedding(tokens.long())*math.sqrt(self.emb_dim)\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,emb_dim:int, dropout:float, maxlen: int = 5000):\n",
    "        super().__init__()\n",
    "\n",
    "        den = torch.exp(-torch.arange(0,emb_dim,2)*math.log(10000)/emb_dim)\n",
    "\n",
    "        pos = torch.arange(0,maxlen).reshape(maxlen,1)\n",
    "        pos_embedding = torch.zeros(size = (maxlen,emb_dim))\n",
    "\n",
    "        pos_embedding[:,0::2]= torch.sin(pos*den)\n",
    "        pos_embedding[:,1::2]= torch.cos(pos*den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2) # add batch size\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding',pos_embedding)\n",
    "\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :]) # take all the rows upto the embedding size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d4f5d3-51e8-45fe-9f4e-426fe8125aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedding(nn.Module):\n",
    "    def __init__(self,vocab_size,emb_dim, dropout = 0.1,train = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding = TokenEmbedding(vocab_size, emb_dim)\n",
    "        self.pos_encoding = PositionalEncoding(emb_dim, dropout)\n",
    "        self.segment_embedding = nn.Embedding(3,emb_dim)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "\n",
    "    def forward(self,bert_inputs, segment_labels = False):\n",
    "        my_embeddings = self.token_embedding(bert_inputs)\n",
    "\n",
    "        if self.train:\n",
    "            x = self.dropout(my_embeddings + self.pos_encoding[:my_embeddings.size(0)]+self.segment_embedding(segment_labels))\n",
    "        else:\n",
    "            x = my_embeddings + self.pos_encoding(my_embeddings)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c7398-becb-40f3-a6d5-f1957574332c",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987095f-4caa-4308-9013-7f686d940a1e",
   "metadata": {},
   "source": [
    "1. Initialization\n",
    "2. Embedding Layer\n",
    "3. Transformer Encoder\n",
    "4. Next Sentence Prediction\n",
    "5. Masked Language Modeling\n",
    "6. Forward Pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7495d2f3-f974-4d83-8f93-a74962ae5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 147161\n",
    "batch = 2\n",
    "count = 0\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    bert_inputs, bert_labels, segment_labels,is_nexts = [b.to(device) for b in batch]\n",
    "    count +=1\n",
    "    if count ==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e39b2654-2bd9-49ab-831e-0ed157572d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 0\n",
      "bert_input: tensor([1, 1], device='mps:0')\n",
      "bert_labels: tensor([0, 0], device='mps:0')\n",
      "segment_labels: tensor([1, 1], device='mps:0')\n",
      "is_nexts: 0\n",
      "sample: 1\n",
      "bert_input: tensor([16, 17], device='mps:0')\n",
      "bert_labels: tensor([0, 0], device='mps:0')\n",
      "segment_labels: tensor([1, 1], device='mps:0')\n",
      "is_nexts: 1\n",
      "sample: 2\n",
      "bert_input: tensor([556,  13], device='mps:0')\n",
      "bert_labels: tensor([0, 0], device='mps:0')\n",
      "segment_labels: tensor([1, 1], device='mps:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert_labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbert_labels[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment_labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment_labels[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_nexts: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mis_nexts[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"sample: {i}\")\n",
    "    print(f\"bert_input: {bert_inputs[i]}\")\n",
    "    print(f\"bert_labels: {bert_labels[i]}\")\n",
    "    print(f\"segment_labels: {segment_labels[i]}\")\n",
    "    print(f\"is_nexts: {is_nexts[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb36e5e5-bd7e-41ff-99b3-001997e91579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "740042aa-9ef4-44c7-b7c8-114b01d39eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a73de7d-bb36-4efd-930f-7c6f2cef7172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_nexts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cbfe0be-4675-4052-aacb-40d8b8fc59bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   1,   16,  556,   17,   24,   20,  594,    3,    8,   16,    3,   65,\n",
       "        1175,    6,    2,   16,   52,  475,    3,   77,   54,   14,   70,   36,\n",
       "         239, 3401,   15,   14,    6,    2,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b440fd2-73fb-45dd-8a15-054ddccbcded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
