{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d91c21-c2a7-4df5-b19e-77ea6537aacb",
   "metadata": {},
   "source": [
    "## BERT's BASICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56029f77-92b9-4867-9e49-ab9da569ba04",
   "metadata": {},
   "source": [
    "BERT's architecture allows for fine tuning specific tasks like:\n",
    "* Text summarization\n",
    "* Question Answering\n",
    "* Sentiment Analysis\n",
    "\n",
    "Uses only `encoder_only` architecture to process entire sequences of text simultaneously\n",
    "`MLM` involves randomly masking some of the input tokens and training BERT to predict the original masked tones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8744ce8-0ab4-45ac-a153-504c3132caeb",
   "metadata": {},
   "source": [
    "For prediction:\n",
    "\n",
    "    * Encoder outputs a set of contextual embeddings\n",
    "    * Contextual embeddings are passed through another layer and converted into a set of logits.\n",
    "    * Masked word is identified by selecting the word corresponding to the index with the highest logit value. \n",
    "\n",
    "Encoder models have access to the entire sequence.\n",
    "\n",
    "The training method is `bidirectional`\n",
    "\n",
    "    * It enables the model to understand the context from both sides of any given word in a sentence.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d24efd-888f-4b51-8499-42d0e8a2e4f7",
   "metadata": {},
   "source": [
    "### Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2d094-c4f8-4f6d-a1e2-a7ef3129368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "\n",
    "# New\n",
    "from torch.nn import Transformer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
