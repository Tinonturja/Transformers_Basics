{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d26fb341-7253-4410-8d25-4ea7b8943ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: = not found\n",
      "zsh:1: = not found\n",
      "Requirement already satisfied: torchtext in /opt/anaconda3/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (4.66.5)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (2.32.3)\n",
      "Requirement already satisfied: torch==2.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (1.26.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.2.2->torchtext) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch==2.2.2->torchtext) (1.3.0)\n",
      "Requirement already satisfied: torchdata in /opt/anaconda3/lib/python3.12/site-packages (0.7.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2->torchdata) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "zsh:1: = not found\n",
      "zsh:1: =2.2.1 not found\n",
      "zsh:1: =3.9.0 not found\n",
      "Requirement already satisfied: transformers==4.35.2 in /opt/anaconda3/lib/python3.12/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy == 1.26.0\n",
    "!pip install torch == 2.2.2 torchvision torchaudio ---url https://download.pytorch.org/whl/cpu\n",
    "!pip install torchtext\n",
    "!pip install torchdata\n",
    "!pip install portalocker == 2.8.2\n",
    "!pip install pandas ==2.2.1\n",
    "!pip install matplotlib ==3.9.0 scikit-learn ==1.5.0\n",
    "!pip install transformers==4.35.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d22ed-7bb3-492a-8879-75d9257848c2",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c7fe0ba-dbdc-4568-814b-5e99f20adbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import multi30k,Multi30k\n",
    "import torch\n",
    "from typing import Iterable, List\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import IMDB,PennTreebank\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3d54de-824a-4ce0-bdcd-3a8ba5ed85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4d2109-844a-4453-b9dc-adea419d80a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_iter)\n",
    "next(data_iter)\n",
    "next(data_iter)\n",
    "next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a492f9-8aed-4e40-b890-43115369ee25",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "* Special Symbols and Indices\n",
    "    * UNK_IDX\n",
    "    * PAD_IDX\n",
    "    * EOS_IDX\n",
    "\n",
    "* yield tokens\n",
    "* create vocabs\n",
    "* Default index for unknown tokens\n",
    "* Text to index\n",
    "* Index to en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5396316-a1aa-4d08-8b85-29b383104ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, EOS_IDX = 0,1,2\n",
    "special_symbols = ['<unk>', '<pad>', '<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59d6ffd-a497-4b13-9596-ae09ed9d1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e8bd69-13f4-4800-ab36-f58c626474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _,data_sample in data_iter:\n",
    "        yield tokenizer(data_sample)\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials = special_symbols, special_first=True)\n",
    "vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d30dd58-d1b4-4684-a860-274b2fe90a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_index = lambda text: [vocab[token] for token in tokenizer(text)]\n",
    "index_to_english = lambda seq_en:\" \".join([vocab.get_itos()[index] for index in seq_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea574725-db98-4964-bac2-41cb119aef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> <pad> <|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_english(torch.tensor([0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0826967f-a247-4a94-8b1a-20bdf7a5d588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<|endoftext|>',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'a',\n",
       " 'and',\n",
       " \"'\",\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'it',\n",
       " 'i',\n",
       " 'in',\n",
       " 'this',\n",
       " 'that',\n",
       " 's',\n",
       " 'was',\n",
       " 'movie',\n",
       " 'for',\n",
       " 'but',\n",
       " 'with',\n",
       " 'as',\n",
       " 't',\n",
       " 'film',\n",
       " 'you',\n",
       " ')',\n",
       " 'on',\n",
       " '(']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = list(vocab.get_itos())[:30]\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf5aab-b9eb-497b-8ed6-88d12671ea46",
   "metadata": {},
   "source": [
    "### Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3756b0-392e-4437-94e3-1088801dafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(block_size, text):\n",
    "    # block size: Context size, how many tokens/indices the model will look after at a time\n",
    "    # text: text is the long sequence of indices.\n",
    "    # Determine the length of the input text\n",
    "    sample_leg = len(text) # Get the total number of tokens in the text\n",
    "\n",
    "    # Calculate the stopping point for randomly selecting a sample\n",
    "    # This ensures the selected sample doesn't exceed the text\n",
    "    random_sample_stop = sample_leg - block_size\n",
    "    # You're calculating how far you can go into the text while still being able to extract a full block_size chunk.\n",
    "\n",
    "\n",
    "    if random_sample_stop >= 1:\n",
    "        random_start = torch.randint(0,random_sample_stop,size = (1,)).item()\n",
    "\n",
    "        stop = random_start + block_size\n",
    "\n",
    "        # Create the input and the target sequence\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop+1]\n",
    "\n",
    "\n",
    "    # Handle the case where the text length is exactly equal to the block size or less than that\n",
    "\n",
    "    elif random_sample_stop<=0:\n",
    "\n",
    "        random_start = 0\n",
    "        stop = sample_leg\n",
    "\n",
    "        src_seq = text[random_start:stop]\n",
    "        trg_seq = text[random_start+1:stop]\n",
    "\n",
    "        # Append an empty string to maintain the sequence alignmenbt\n",
    "        trg_seq.append('<|endoftext>|')\n",
    "\n",
    "\n",
    "    return src_seq,trg_seq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f62dabf8-c592-45f5-a127-cfacd6a32ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "batch_of_tokens = []\n",
    "\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    _,text = next(iter(train_iter))\n",
    "    batch_of_tokens.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3333a5-41d7-4119-a999-dc7d8ff448aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f03694c7-bfb6-4b43-b1b9-096a0a8c6f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'rented',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'from',\n",
       "  'my',\n",
       "  'video',\n",
       "  'store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it',\n",
       "  'when',\n",
       "  'it',\n",
       "  'was',\n",
       "  'first',\n",
       "  'released',\n",
       "  'in',\n",
       "  '1967',\n",
       "  '.',\n",
       "  'i',\n",
       "  'also',\n",
       "  'heard',\n",
       "  'that',\n",
       "  'at',\n",
       "  'first',\n",
       "  'it',\n",
       "  'was',\n",
       "  'seized',\n",
       "  'by',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'customs',\n",
       "  'if',\n",
       "  'it',\n",
       "  'ever',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'this',\n",
       "  'country',\n",
       "  ',',\n",
       "  'therefore',\n",
       "  'being',\n",
       "  'a',\n",
       "  'fan',\n",
       "  'of',\n",
       "  'films',\n",
       "  'considered',\n",
       "  'controversial',\n",
       "  'i',\n",
       "  'really',\n",
       "  'had',\n",
       "  'to',\n",
       "  'see',\n",
       "  'this',\n",
       "  'for',\n",
       "  'myself',\n",
       "  '.',\n",
       "  'the',\n",
       "  'plot',\n",
       "  'is',\n",
       "  'centered',\n",
       "  'around',\n",
       "  'a',\n",
       "  'young',\n",
       "  'swedish',\n",
       "  'drama',\n",
       "  'student',\n",
       "  'named',\n",
       "  'lena',\n",
       "  'who',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'everything',\n",
       "  'she',\n",
       "  'can',\n",
       "  'about',\n",
       "  'life',\n",
       "  '.',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'focus',\n",
       "  'her',\n",
       "  'attentions',\n",
       "  'to',\n",
       "  'making',\n",
       "  'some',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'documentary',\n",
       "  'on',\n",
       "  'what',\n",
       "  'the',\n",
       "  'average',\n",
       "  'swede',\n",
       "  'thought',\n",
       "  'about',\n",
       "  'certain',\n",
       "  'political',\n",
       "  'issues',\n",
       "  'such',\n",
       "  'as',\n",
       "  'the',\n",
       "  'vietnam',\n",
       "  'war',\n",
       "  'and',\n",
       "  'race',\n",
       "  'issues',\n",
       "  'in',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  '.',\n",
       "  'in',\n",
       "  'between',\n",
       "  'asking',\n",
       "  'politicians',\n",
       "  'and',\n",
       "  'ordinary',\n",
       "  'denizens',\n",
       "  'of',\n",
       "  'stockholm',\n",
       "  'about',\n",
       "  'their',\n",
       "  'opinions',\n",
       "  'on',\n",
       "  'politics',\n",
       "  ',',\n",
       "  'she',\n",
       "  'has',\n",
       "  'sex',\n",
       "  'with',\n",
       "  'her',\n",
       "  'drama',\n",
       "  'teacher',\n",
       "  ',',\n",
       "  'classmates',\n",
       "  ',',\n",
       "  'and',\n",
       "  'married',\n",
       "  'men',\n",
       "  '.',\n",
       "  'what',\n",
       "  'kills',\n",
       "  'me',\n",
       "  'about',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'is',\n",
       "  'that',\n",
       "  '40',\n",
       "  'years',\n",
       "  'ago',\n",
       "  ',',\n",
       "  'this',\n",
       "  'was',\n",
       "  'considered',\n",
       "  'pornographic',\n",
       "  '.',\n",
       "  'really',\n",
       "  ',',\n",
       "  'the',\n",
       "  'sex',\n",
       "  'and',\n",
       "  'nudity',\n",
       "  'scenes',\n",
       "  'are',\n",
       "  'few',\n",
       "  'and',\n",
       "  'far',\n",
       "  'between',\n",
       "  ',',\n",
       "  'even',\n",
       "  'then',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'not',\n",
       "  'shot',\n",
       "  'like',\n",
       "  'some',\n",
       "  'cheaply',\n",
       "  'made',\n",
       "  'porno',\n",
       "  '.',\n",
       "  'while',\n",
       "  'my',\n",
       "  'countrymen',\n",
       "  'mind',\n",
       "  'find',\n",
       "  'it',\n",
       "  'shocking',\n",
       "  ',',\n",
       "  'in',\n",
       "  'reality',\n",
       "  'sex',\n",
       "  'and',\n",
       "  'nudity',\n",
       "  'are',\n",
       "  'a',\n",
       "  'major',\n",
       "  'staple',\n",
       "  'in',\n",
       "  'swedish',\n",
       "  'cinema',\n",
       "  '.',\n",
       "  'even',\n",
       "  'ingmar',\n",
       "  'bergman',\n",
       "  ',',\n",
       "  'arguably',\n",
       "  'their',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'good',\n",
       "  'old',\n",
       "  'boy',\n",
       "  'john',\n",
       "  'ford',\n",
       "  ',',\n",
       "  'had',\n",
       "  'sex',\n",
       "  'scenes',\n",
       "  'in',\n",
       "  'his',\n",
       "  'films',\n",
       "  '.',\n",
       "  'i',\n",
       "  'do',\n",
       "  'commend',\n",
       "  'the',\n",
       "  'filmmakers',\n",
       "  'for',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'any',\n",
       "  'sex',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'the',\n",
       "  'film',\n",
       "  'is',\n",
       "  'shown',\n",
       "  'for',\n",
       "  'artistic',\n",
       "  'purposes',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'just',\n",
       "  'to',\n",
       "  'shock',\n",
       "  'people',\n",
       "  'and',\n",
       "  'make',\n",
       "  'money',\n",
       "  'to',\n",
       "  'be',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'pornographic',\n",
       "  'theaters',\n",
       "  'in',\n",
       "  'america',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'is',\n",
       "  'a',\n",
       "  'good',\n",
       "  'film',\n",
       "  'for',\n",
       "  'anyone',\n",
       "  'wanting',\n",
       "  'to',\n",
       "  'study',\n",
       "  'the',\n",
       "  'meat',\n",
       "  'and',\n",
       "  'potatoes',\n",
       "  '(',\n",
       "  'no',\n",
       "  'pun',\n",
       "  'intended',\n",
       "  ')',\n",
       "  'of',\n",
       "  'swedish',\n",
       "  'cinema',\n",
       "  '.',\n",
       "  'but',\n",
       "  'really',\n",
       "  ',',\n",
       "  'this',\n",
       "  'film',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'have',\n",
       "  'much',\n",
       "  'of',\n",
       "  'a',\n",
       "  'plot',\n",
       "  '.']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = batch_of_tokens[0][0:100]\n",
    "text[0:100]\n",
    "batch_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41245ce6-6423-41fc-b7b6-a0cb1c420c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be1db85a-e374-4731-aae3-da73b162bb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2ab707b-6d35-4e0f-bdba-37bc4acc4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 10\n",
    "src_seq,trg_seq = get_sample(block_size,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0e97bec-d8d8-480b-a38d-95d79bf29a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['video',\n",
       "  'store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it'],\n",
       " ['store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it',\n",
       "  'when'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq,trg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e3d3bc1-6427-43cd-8040-f0ec7cfbc8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: ['video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it']\n",
      "trg: ['store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when']\n"
     ]
    }
   ],
   "source": [
    "print(f\"src: {src_seq}\")\n",
    "print(f\"trg: {trg_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c638983-9cdc-41f8-b7ac-ebc7af992f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "Source Sequence (Text): ['seized', 'by', 'u', '.', 's', '.', 'customs', 'if', 'it', 'ever']\n",
      "Source Sequence (Indices): [17608, 46, 1466, 3, 17, 3, 11063, 51, 12, 124]\n",
      "Source Sequence (Shape): torch.Size([10])\n",
      "Target Sequence (Text): ['by', 'u', '.', 's', '.', 'customs', 'if', 'it', 'ever', 'tried']\n",
      "Target Sequence (Indices): [46, 1466, 3, 17, 3, 11063, 51, 12, 124, 608]\n",
      "Target Sequence (Shape): torch.Size([10])\n",
      "Sample 1\n",
      "Source Sequence (Text): ['scenes', 'in', 'his', 'films', '.', 'i', 'do', 'commend', 'the', 'filmmakers']\n",
      "Source Sequence (Indices): [144, 14, 39, 129, 3, 13, 81, 11638, 4, 839]\n",
      "Source Sequence (Shape): torch.Size([10])\n",
      "Target Sequence (Text): ['in', 'his', 'films', '.', 'i', 'do', 'commend', 'the', 'filmmakers', 'for']\n",
      "Target Sequence (Indices): [14, 39, 129, 3, 13, 81, 11638, 4, 839, 20]\n",
      "Target Sequence (Shape): torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store source and target\n",
    "src_batch,trg_batch = [],[]\n",
    "\n",
    "# Define batch size\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# Loop to create batches of source and target sequence\n",
    "for i in range(BATCH_SIZE):\n",
    "    _, text = next(iter(train_iter))\n",
    "\n",
    "    # Generate source and target sequences using the get_sample \n",
    "    src_sequence_text, tgt_sequence_text = get_sample(block_size,tokenizer(text))\n",
    "\n",
    "\n",
    "    # Convert source and target sequences to tokenized vocabulary indices\n",
    "    src_sequence_indices = vocab(src_sequence_text)\n",
    "\n",
    "    tgt_sequence_indices = vocab(tgt_sequence_text)\n",
    "\n",
    "    # Convert the sequences to PyTorch Tensors with dtype int64\n",
    "    src_sequence = torch.tensor(src_sequence_indices)\n",
    "    tgt_sequence = torch.tensor(tgt_sequence_indices)\n",
    "\n",
    "    # Append the source and target sequences to their respective batches\n",
    "    src_batch.append(src_sequence)\n",
    "    trg_batch.append(tgt_sequence)\n",
    "\n",
    "    # Print the output for every 2nd sample\n",
    "    print(f\"Sample {i}\")\n",
    "    print(f\"Source Sequence (Text): {src_sequence_text}\")\n",
    "    print(f\"Source Sequence (Indices): {src_sequence_indices}\")\n",
    "    print(f\"Source Sequence (Shape): {src_sequence.shape}\")\n",
    "    print(f\"Target Sequence (Text): {tgt_sequence_text}\")\n",
    "    print(f\"Target Sequence (Indices): {tgt_sequence_indices}\")\n",
    "    print(f\"Target Sequence (Shape): {tgt_sequence.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fc7efc4-da3e-4baf-9295-0a8c26c54332",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 30\n",
    "\n",
    "def collate_batch(batch):\n",
    "\n",
    "    src_batch,tgt_batch = [], []\n",
    "\n",
    "    for _,text in batch:\n",
    "        tokens = tokenizer(text)\n",
    "        src_tokens,tgt_tokens = get_sample(block_size,tokens)\n",
    "        src_indices,tgt_indices = vocab(src_tokens),vocab(tgt_tokens)\n",
    "        src_sequences,tgt_sequences = torch.tensor(src_indices,dtype = torch.int64),torch.tensor(tgt_indices,dtype = torch.int64)\n",
    "        src_batch.append(src_sequences)\n",
    "        tgt_batch.append(tgt_sequences)\n",
    "\n",
    "\n",
    "    src_batch = pad_sequence(src_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "    tgt_batch = pad_sequence(tgt_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "\n",
    "    return src_batch.to(DEVICE),tgt_batch.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c4c0686-8f1a-4ed9-b55c-a782c94754d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da578e3a-26df-448d-8088-02f962a0f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_iter,\n",
    "                       batch_size =BATCH_SIZE,\n",
    "                       shuffle = True,\n",
    "                       collate_fn = collate_batch)\n",
    "\n",
    "val_dataloader = DataLoader(valid_iter,\n",
    "                       batch_size =BATCH_SIZE,\n",
    "                       shuffle = True,\n",
    "                       collate_fn = collate_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e2485-e702-42d2-ae6e-506680ca92b5",
   "metadata": {},
   "source": [
    "## Iterating Through Data Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598263d9-af37-4213-ade8-909b179336a7",
   "metadata": {},
   "source": [
    "`dataset`, an iterator is formed to run over the dataloader, which in return provide src and tgt pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db9e35fe-19bf-455c-a78e-d9bfe8e3485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "sorce: s keen aspiration to pay homage to ozu on his\n",
      "\n",
      "\n",
      "target: keen aspiration to pay homage to ozu on his centenary\n",
      "\n",
      "\n",
      "sample 1\n",
      "sorce: to be an ankylosaur seriously ? and the tyrannosaur seems\n",
      "\n",
      "\n",
      "target: be an ankylosaur seriously ? and the tyrannosaur seems rooted\n",
      "\n",
      "\n",
      "sample 2\n",
      "sorce: annoying . and the saddest thing is the movie is\n",
      "\n",
      "\n",
      "target: . and the saddest thing is the movie is too\n",
      "\n",
      "\n",
      "sample 3\n",
      "sorce: this move had , the reality was disappointing . while\n",
      "\n",
      "\n",
      "target: move had , the reality was disappointing . while it\n",
      "\n",
      "\n",
      "sample 4\n",
      "sorce: i kept watching this hoping that i could see why\n",
      "\n",
      "\n",
      "target: kept watching this hoping that i could see why it\n",
      "\n",
      "\n",
      "sample 5\n",
      "sorce: mr . dark , what happened to mr . coogan\n",
      "\n",
      "\n",
      "target: . dark , what happened to mr . coogan on\n",
      "\n",
      "\n",
      "sample 6\n",
      "sorce: dont know who wrote the script but i bet they\n",
      "\n",
      "\n",
      "target: know who wrote the script but i bet they got\n",
      "\n",
      "\n",
      "sample 7\n",
      "sorce: . it seems to me whomever made this movie is\n",
      "\n",
      "\n",
      "target: it seems to me whomever made this movie is afflicted\n",
      "\n",
      "\n",
      "sample 8\n",
      "sorce: line by filling this movie with totally unsympathetic and almost\n",
      "\n",
      "\n",
      "target: by filling this movie with totally unsympathetic and almost masochistic\n",
      "\n",
      "\n",
      "sample 9\n",
      "sorce: . . . oh wait i must be thinking of\n",
      "\n",
      "\n",
      "target: . . oh wait i must be thinking of a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = iter(dataloader)\n",
    "for sample in range(10):\n",
    "    src,tgt = next(dataset)\n",
    "    print(\"sample\",sample)\n",
    "    print(\"sorce:\",index_to_en(src))\n",
    "    print(\"\\n\")\n",
    "    print(\"target:\",index_to_en(tgt))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06d930d6-2e6f-46b8-bf40-a3ed09918182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_en(batch):\n",
    "    return \" \".join([vocab.get_itos()[idx] for idx in batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7aac78-2e42-42a4-9b79-09c4be2476df",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8541e55e-e919-4054-baac-82ade95ee262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz,device = DEVICE):\n",
    "    mask = (torch.triu(torch.ones((sz,sz),device = device))==1).transpose(0,1)\n",
    "    mask = mask.float().masked_fill(mask ==0,float ('-inf')).masked_fill(mask ==1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4cab571-f237-45b5-8c23-10f7bffed50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src, device = DEVICE):\n",
    "    src_seq_len = src.shape[0]\n",
    "    src_mask = generate_square_subsequent_mask(src_seq_len)\n",
    "    src_padding_mask = (src ==PAD_IDX).transpose(0,1)\n",
    "    return src_mask,src_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee527d4-17b3-4ae2-88d7-0f7bb67ebf3c",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "598dc4cb-5107-4bc3-be11-d26c725d91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                emb_dim: int,\n",
    "                dropout: float,\n",
    "                maxlen: int = 5000):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        den = torch.exp(-torch.arange(0,emb_dim,2)*math.log(10000)/emb_dim)\n",
    "        pos = torch.arange(0,maxlen).reshape(maxlen,1)\n",
    "        pos_embedding = torch.zeros(size = (maxlen,emb_dim))\n",
    "\n",
    "        pos_embedding[:,0::2] = torch.sin(pos*den)\n",
    "        pos_embedding[:,0::2] = torch.cos(pos*den)\n",
    "\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self,token_embeding):\n",
    "        return self.dropout(token_embedding +self.pos_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c0d65-70df-46a5-bad0-6e11c2dbcbf5",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3523767-d1c8-4e99-8a84-70e6c615b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,emb_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def forward(self,tokens):\n",
    "\n",
    "        return self.embedding(tokens.long())* math.sqrt(self.emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53900747-0c20-49aa-b7ad-e930de1d90a0",
   "metadata": {},
   "source": [
    "## Custom GPT model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead70349-548d-4561-aabe-a839d309f8b1",
   "metadata": {},
   "source": [
    "* Initialization (__init__): embed_size, vocab_size, num_heads,num_layers,max_seq_len and dropout\n",
    "* lm_head: generating logits over the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23af57-f0d5-46bc-ae7b-013cbbb1ace5",
   "metadata": {},
   "source": [
    "* **Weight initialization** initializes the weights of the model for better training convergence. The Xavier uniform initialization is used, which is a common practice for initializing weights in deep learning\n",
    "* **Decoder** Although named `'decoder'`, this method currently functions as the forward pass through the transformer encoder layers, followed by the generation of `logits` for the language modelling task. It handles the addition of positional encodings to the embeddings and applies a mask if necessary.\n",
    "* **Forward pass**: This method is similar to the `decoder` method, and defines the forward computation of the model. It produces the input through embedding layers, positional encoding, transformer encoder layers, and produces the final output using the `lm_head`\n",
    "* **Mask Generation:** Both **decoder** and **forward** methods contain logic to generate a square causal mask if no source mask is provided.\n",
    "mask ensures that the prediction for a position does not depend on the future tokens in the sequence, which is important for the autoregressive nature of gpt models.\n",
    "* **Commented Out Decoder**: A section of the code is commented out, suggesting an initial design where a transformer decoder layer was considered. However, the final implementation uses only encoder layers, which is a common simplification for models focusing on language modeling and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1ba59-0bba-4c86-ae15-6058a33196e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self,emb_dim:int,\n",
    "                vocab_size: int,\n",
    "                num_heads: int,\n",
    "                num_layers: int,\n",
    "                max_seq_len = 500,\n",
    "                 dropout = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(emb_dim = emb_dim,\n",
    "                                                     dropout = dropout)\n",
    "\n",
    "        print(emb_dim)\n",
    "\n",
    "        # Remaining layers are part of the TransformerDecoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model = emb_dim,\n",
    "                                                   nhead = num_heads,\n",
    "                                                   dropout = dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layers,\n",
    "                                                        num_layers=num_layers)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size) # produce the final output, the final logits over the vocabulary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim()>1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def create_mask(src, device = DEVICE):\n",
    "        src_seq_len = src.shape[0]\n",
    "        src_mask = nn.Transformer.generate_square_subsequent_mask(src_seq_len)\n",
    "        src_padding_mask = (src ==PAD_IDX).transpose(0,1)\n",
    "        return src_mask, src_padding_mask\n",
    "\n",
    "    def decoder(self, x, src_mask):\n",
    "        seq_len = x.size(0)\n",
    "\n",
    "\n",
    "        # Add positional embeddings to the input embeddings\n",
    "        x = self.embed(x)*math.sqrt(self.emb_dim)\n",
    "\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "\n",
    "        if src_mask is None:\n",
    "            \"\"\"Generate a square casual mask for the sequence. The masked positions are filled with -inf and the unmasked postions will be filled with 0\"\"\"\n",
    "\n",
    "            src_mask, src_padding_mask =create_mask(x)\n",
    "\n",
    "        output = self.transformer_encoder(x,src_mask)\n",
    "        logits = self.lm_head(output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def forward(self,x, src_mask = None, key_padding_mask = None):\n",
    "\n",
    "        seq_length = x.size(0)\n",
    "\n",
    "        embedding = self.embed(x) * math.sqrt(self.emb_dim)\n",
    "        x = self.positional_encoding(embedding)\n",
    "\n",
    "        if src_mask is None:\n",
    "            src_mask,src_padding_mask = create_mask(x)\n",
    "\n",
    "        output = self.transformer_encoder(x,src_mask, )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3f4309b-7e11-498c-9d96-bb26cdb5e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87308fbb-d38e-4424-9f37-f1ff69c1e1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf50e4-ebda-4403-a811-d2de96385de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93576263-320c-478b-a6ea-1adce12e32bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_t = torch.ones(3,3)\n",
    "one_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73653b1-201b-45f1-8355-fd40d0c30060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db049ed4-20ae-4614-98b8-a00fa9925680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75f2b9fe-04b4-4f40-9e94-4674ee0f43d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_t = torch.triu(one_t)\n",
    "upper_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ae95385-f6ce-48d4-a0dc-c368560918a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True],\n",
       "        [False,  True,  True],\n",
       "        [False, False,  True]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru = upper_t==1\n",
    "tru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9d54b85-d06e-45c9-8a0d-b070559bb1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru_trans = tru.transpose(0,1)\n",
    "tru_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8312459-c946-456f-91ef-7e0e6f8a924f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
