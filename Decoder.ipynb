{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d26fb341-7253-4410-8d25-4ea7b8943ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: = not found\n",
      "zsh:1: = not found\n",
      "Requirement already satisfied: torchtext in /opt/anaconda3/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (4.66.5)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (2.32.3)\n",
      "Requirement already satisfied: torch==2.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (1.26.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.2.2->torchtext) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch==2.2.2->torchtext) (1.3.0)\n",
      "Requirement already satisfied: torchdata in /opt/anaconda3/lib/python3.12/site-packages (0.7.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in /opt/anaconda3/lib/python3.12/site-packages (from torchdata) (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2->torchdata) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchdata) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2->torchdata) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "zsh:1: = not found\n",
      "zsh:1: =2.2.1 not found\n",
      "zsh:1: =3.9.0 not found\n",
      "Collecting transformers==4.35.2\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2)\n",
      "  Downloading tokenizers-0.15.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.35.2) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.35.2) (2025.4.26)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading tokenizers-0.15.2-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.35.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy == 1.26.0\n",
    "!pip install torch == 2.2.2 torchvision torchaudio ---url https://download.pytorch.org/whl/cpu\n",
    "!pip install torchtext\n",
    "!pip install torchdata\n",
    "!pip install portalocker == 2.8.2\n",
    "!pip install pandas ==2.2.1\n",
    "!pip install matplotlib ==3.9.0 scikit-learn ==1.5.0\n",
    "!pip install transformers==4.35.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d22ed-7bb3-492a-8879-75d9257848c2",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7fe0ba-dbdc-4568-814b-5e99f20adbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import multi30k,Multi30k\n",
    "import torch\n",
    "from typing import Iterable, List\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import IMDB,PennTreebank\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3d54de-824a-4ce0-bdcd-3a8ba5ed85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4d2109-844a-4453-b9dc-adea419d80a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_iter)\n",
    "next(data_iter)\n",
    "next(data_iter)\n",
    "next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a492f9-8aed-4e40-b890-43115369ee25",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "* Special Symbols and Indices\n",
    "    * UNK_IDX\n",
    "    * PAD_IDX\n",
    "    * EOS_IDX\n",
    "\n",
    "* yield tokens\n",
    "* create vocabs\n",
    "* Default index for unknown tokens\n",
    "* Text to index\n",
    "* Index to en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5396316-a1aa-4d08-8b85-29b383104ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, EOS_IDX = 0,1,2\n",
    "special_symbols = ['<unk>', '<pad>', '<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59d6ffd-a497-4b13-9596-ae09ed9d1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e8bd69-13f4-4800-ab36-f58c626474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _,data_sample in data_iter:\n",
    "        yield tokenizer(data_sample)\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials = special_symbols, special_first=True)\n",
    "vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d30dd58-d1b4-4684-a860-274b2fe90a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_index = lambda text: [vocab[token] for token in tokenizer(text)]\n",
    "index_to_english = lambda seq_en:\" \".join([vocab.get_itos()[index] for index in seq_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea574725-db98-4964-bac2-41cb119aef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> <pad> <|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_english(torch.tensor([0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0826967f-a247-4a94-8b1a-20bdf7a5d588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<|endoftext|>',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'a',\n",
       " 'and',\n",
       " \"'\",\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'it',\n",
       " 'i',\n",
       " 'in',\n",
       " 'this',\n",
       " 'that',\n",
       " 's',\n",
       " 'was',\n",
       " 'movie',\n",
       " 'for',\n",
       " 'but',\n",
       " 'with',\n",
       " 'as',\n",
       " 't',\n",
       " 'film',\n",
       " 'you',\n",
       " ')',\n",
       " 'on',\n",
       " '(']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = list(vocab.get_itos())[:30]\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf5aab-b9eb-497b-8ed6-88d12671ea46",
   "metadata": {},
   "source": [
    "### Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3756b0-392e-4437-94e3-1088801dafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(block_size, text):\n",
    "    # block size: Context size, how many tokens/indices the model will look after at a time\n",
    "    # text: text is the long sequence of indices.\n",
    "    # Determine the length of the input text\n",
    "    sample_leg = len(text) # Get the total number of tokens in the text\n",
    "\n",
    "    # Calculate the stopping point for randomly selecting a sample\n",
    "    # This ensures the selected sample doesn't exceed the text\n",
    "    random_sample_stop = sample_leg - block_size\n",
    "    # You're calculating how far you can go into the text while still being able to extract a full block_size chunk.\n",
    "\n",
    "\n",
    "    if random_sample_stop >= 1:\n",
    "        random_start = torch.randint(0,random_sample_stop,size = (1,)).item()\n",
    "\n",
    "        stop = random_start + block_size\n",
    "\n",
    "        # Create the input and the target sequence\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop+1]\n",
    "\n",
    "\n",
    "    # Handle the case where the text length is exactly equal to the block size or less than that\n",
    "\n",
    "    elif random_sample_stop<=0:\n",
    "\n",
    "        random_start = 0\n",
    "        stop = sample_leg\n",
    "\n",
    "        src_seq = text[random_start:stop]\n",
    "        trg_seq = text[random_start+1:stop]\n",
    "\n",
    "        # Append an empty string to maintain the sequence alignmenbt\n",
    "        trg_seq.append('<|endoftext>|')\n",
    "\n",
    "\n",
    "    return src_seq,trg_seq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f62dabf8-c592-45f5-a127-cfacd6a32ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "batch_of_tokens = []\n",
    "\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    _,text = next(iter(train_iter))\n",
    "    batch_of_tokens.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e3333a5-41d7-4119-a999-dc7d8ff448aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'rented',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'from',\n",
       "  'my',\n",
       "  'video',\n",
       "  'store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it',\n",
       "  'when',\n",
       "  'it',\n",
       "  'was',\n",
       "  'first',\n",
       "  'released',\n",
       "  'in',\n",
       "  '1967',\n",
       "  '.',\n",
       "  'i',\n",
       "  'also',\n",
       "  'heard',\n",
       "  'that',\n",
       "  'at',\n",
       "  'first',\n",
       "  'it',\n",
       "  'was',\n",
       "  'seized',\n",
       "  'by',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'customs',\n",
       "  'if',\n",
       "  'it',\n",
       "  'ever',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'this',\n",
       "  'country',\n",
       "  ',',\n",
       "  'therefore',\n",
       "  'being',\n",
       "  'a',\n",
       "  'fan',\n",
       "  'of',\n",
       "  'films',\n",
       "  'considered',\n",
       "  'controversial',\n",
       "  'i',\n",
       "  'really',\n",
       "  'had',\n",
       "  'to',\n",
       "  'see',\n",
       "  'this',\n",
       "  'for',\n",
       "  'myself',\n",
       "  '.',\n",
       "  'the',\n",
       "  'plot',\n",
       "  'is',\n",
       "  'centered',\n",
       "  'around',\n",
       "  'a',\n",
       "  'young',\n",
       "  'swedish',\n",
       "  'drama',\n",
       "  'student',\n",
       "  'named',\n",
       "  'lena',\n",
       "  'who',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'everything',\n",
       "  'she',\n",
       "  'can',\n",
       "  'about',\n",
       "  'life',\n",
       "  '.',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'focus',\n",
       "  'her',\n",
       "  'attentions',\n",
       "  'to',\n",
       "  'making',\n",
       "  'some',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'documentary',\n",
       "  'on',\n",
       "  'what',\n",
       "  'the',\n",
       "  'average',\n",
       "  'swede',\n",
       "  'thought',\n",
       "  'about',\n",
       "  'certain',\n",
       "  'political',\n",
       "  'issues',\n",
       "  'such',\n",
       "  'as',\n",
       "  'the',\n",
       "  'vietnam',\n",
       "  'war',\n",
       "  'and',\n",
       "  'race',\n",
       "  'issues',\n",
       "  'in',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  '.',\n",
       "  'in',\n",
       "  'between',\n",
       "  'asking',\n",
       "  'politicians',\n",
       "  'and',\n",
       "  'ordinary',\n",
       "  'denizens',\n",
       "  'of',\n",
       "  'stockholm',\n",
       "  'about',\n",
       "  'their',\n",
       "  'opinions',\n",
       "  'on',\n",
       "  'politics',\n",
       "  ',',\n",
       "  'she',\n",
       "  'has',\n",
       "  'sex',\n",
       "  'with',\n",
       "  'her',\n",
       "  'drama',\n",
       "  'teacher',\n",
       "  ',',\n",
       "  'classmates',\n",
       "  ',',\n",
       "  'and',\n",
       "  'married',\n",
       "  'men',\n",
       "  '.',\n",
       "  'what',\n",
       "  'kills',\n",
       "  'me',\n",
       "  'about',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'is',\n",
       "  'that',\n",
       "  '40',\n",
       "  'years',\n",
       "  'ago',\n",
       "  ',',\n",
       "  'this',\n",
       "  'was',\n",
       "  'considered',\n",
       "  'pornographic',\n",
       "  '.',\n",
       "  'really',\n",
       "  ',',\n",
       "  'the',\n",
       "  'sex',\n",
       "  'and',\n",
       "  'nudity',\n",
       "  'scenes',\n",
       "  'are',\n",
       "  'few',\n",
       "  'and',\n",
       "  'far',\n",
       "  'between',\n",
       "  ',',\n",
       "  'even',\n",
       "  'then',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'not',\n",
       "  'shot',\n",
       "  'like',\n",
       "  'some',\n",
       "  'cheaply',\n",
       "  'made',\n",
       "  'porno',\n",
       "  '.',\n",
       "  'while',\n",
       "  'my',\n",
       "  'countrymen',\n",
       "  'mind',\n",
       "  'find',\n",
       "  'it',\n",
       "  'shocking',\n",
       "  ',',\n",
       "  'in',\n",
       "  'reality',\n",
       "  'sex',\n",
       "  'and',\n",
       "  'nudity',\n",
       "  'are',\n",
       "  'a',\n",
       "  'major',\n",
       "  'staple',\n",
       "  'in',\n",
       "  'swedish',\n",
       "  'cinema',\n",
       "  '.',\n",
       "  'even',\n",
       "  'ingmar',\n",
       "  'bergman',\n",
       "  ',',\n",
       "  'arguably',\n",
       "  'their',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'good',\n",
       "  'old',\n",
       "  'boy',\n",
       "  'john',\n",
       "  'ford',\n",
       "  ',',\n",
       "  'had',\n",
       "  'sex',\n",
       "  'scenes',\n",
       "  'in',\n",
       "  'his',\n",
       "  'films',\n",
       "  '.',\n",
       "  'i',\n",
       "  'do',\n",
       "  'commend',\n",
       "  'the',\n",
       "  'filmmakers',\n",
       "  'for',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'any',\n",
       "  'sex',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'the',\n",
       "  'film',\n",
       "  'is',\n",
       "  'shown',\n",
       "  'for',\n",
       "  'artistic',\n",
       "  'purposes',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'just',\n",
       "  'to',\n",
       "  'shock',\n",
       "  'people',\n",
       "  'and',\n",
       "  'make',\n",
       "  'money',\n",
       "  'to',\n",
       "  'be',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'pornographic',\n",
       "  'theaters',\n",
       "  'in',\n",
       "  'america',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'is',\n",
       "  'a',\n",
       "  'good',\n",
       "  'film',\n",
       "  'for',\n",
       "  'anyone',\n",
       "  'wanting',\n",
       "  'to',\n",
       "  'study',\n",
       "  'the',\n",
       "  'meat',\n",
       "  'and',\n",
       "  'potatoes',\n",
       "  '(',\n",
       "  'no',\n",
       "  'pun',\n",
       "  'intended',\n",
       "  ')',\n",
       "  'of',\n",
       "  'swedish',\n",
       "  'cinema',\n",
       "  '.',\n",
       "  'but',\n",
       "  'really',\n",
       "  ',',\n",
       "  'this',\n",
       "  'film',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'have',\n",
       "  'much',\n",
       "  'of',\n",
       "  'a',\n",
       "  'plot',\n",
       "  '.']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26d37b-cb9b-4670-875c-25282540d06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
