{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34d22ed-7bb3-492a-8879-75d9257848c2",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c7fe0ba-dbdc-4568-814b-5e99f20adbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import multi30k,Multi30k\n",
    "import torch\n",
    "from typing import Iterable, List\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import IMDB,PennTreebank\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3d54de-824a-4ce0-bdcd-3a8ba5ed85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4d2109-844a-4453-b9dc-adea419d80a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_iter)\n",
    "next(data_iter)\n",
    "next(data_iter)\n",
    "next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a492f9-8aed-4e40-b890-43115369ee25",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "* Special Symbols and Indices\n",
    "    * UNK_IDX\n",
    "    * PAD_IDX\n",
    "    * EOS_IDX\n",
    "\n",
    "* yield tokens\n",
    "* create vocabs\n",
    "* Default index for unknown tokens\n",
    "* Text to index\n",
    "* Index to en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5396316-a1aa-4d08-8b85-29b383104ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, EOS_IDX = 0,1,2\n",
    "special_symbols = ['<unk>', '<pad>', '<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59d6ffd-a497-4b13-9596-ae09ed9d1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e8bd69-13f4-4800-ab36-f58c626474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _,data_sample in data_iter:\n",
    "        yield tokenizer(data_sample)\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials = special_symbols, special_first=True)\n",
    "vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d30dd58-d1b4-4684-a860-274b2fe90a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_index = lambda text: [vocab[token] for token in tokenizer(text)]\n",
    "index_to_english = lambda seq_en:\" \".join([vocab.get_itos()[index] for index in seq_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea574725-db98-4964-bac2-41cb119aef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> <pad> <|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_english(torch.tensor([0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0826967f-a247-4a94-8b1a-20bdf7a5d588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<|endoftext|>',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'a',\n",
       " 'and',\n",
       " \"'\",\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'it',\n",
       " 'i',\n",
       " 'in',\n",
       " 'this',\n",
       " 'that',\n",
       " 's',\n",
       " 'was',\n",
       " 'movie',\n",
       " 'for',\n",
       " 'but',\n",
       " 'with',\n",
       " 'as',\n",
       " 't',\n",
       " 'film',\n",
       " 'you',\n",
       " ')',\n",
       " 'on',\n",
       " '(']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = list(vocab.get_itos())[:30]\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf5aab-b9eb-497b-8ed6-88d12671ea46",
   "metadata": {},
   "source": [
    "### Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3756b0-392e-4437-94e3-1088801dafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(block_size, text):\n",
    "    # block size: Context size, how many tokens/indices the model will look after at a time\n",
    "    # text: text is the long sequence of indices.\n",
    "    # Determine the length of the input text\n",
    "    sample_leg = len(text) # Get the total number of tokens in the text\n",
    "\n",
    "    # Calculate the stopping point for randomly selecting a sample\n",
    "    # This ensures the selected sample doesn't exceed the text\n",
    "    random_sample_stop = sample_leg - block_size\n",
    "    # You're calculating how far you can go into the text while still being able to extract a full block_size chunk.\n",
    "\n",
    "\n",
    "    if random_sample_stop >= 1:\n",
    "        random_start = torch.randint(0,random_sample_stop,size = (1,)).item()\n",
    "\n",
    "        stop = random_start + block_size\n",
    "\n",
    "        # Create the input and the target sequence\n",
    "        src_seq = text[random_start:stop]\n",
    "\n",
    "        trg_seq = text[random_start+1:stop+1]\n",
    "\n",
    "\n",
    "    # Handle the case where the text length is exactly equal to the block size or less than that\n",
    "\n",
    "    elif random_sample_stop<=0:\n",
    "\n",
    "        random_start = 0\n",
    "        stop = sample_leg\n",
    "\n",
    "        src_seq = text[random_start:stop]\n",
    "        trg_seq = text[random_start+1:stop]\n",
    "\n",
    "        # Append an empty string to maintain the sequence alignmenbt\n",
    "        trg_seq.append('<|endoftext>|')\n",
    "\n",
    "\n",
    "    return src_seq,trg_seq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f62dabf8-c592-45f5-a127-cfacd6a32ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "batch_of_tokens = []\n",
    "\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    _,text = next(iter(train_iter))\n",
    "    batch_of_tokens.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3333a5-41d7-4119-a999-dc7d8ff448aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f03694c7-bfb6-4b43-b1b9-096a0a8c6f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'rented',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'from',\n",
       "  'my',\n",
       "  'video',\n",
       "  'store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it',\n",
       "  'when',\n",
       "  'it',\n",
       "  'was',\n",
       "  'first',\n",
       "  'released',\n",
       "  'in',\n",
       "  '1967',\n",
       "  '.',\n",
       "  'i',\n",
       "  'also',\n",
       "  'heard',\n",
       "  'that',\n",
       "  'at',\n",
       "  'first',\n",
       "  'it',\n",
       "  'was',\n",
       "  'seized',\n",
       "  'by',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'customs',\n",
       "  'if',\n",
       "  'it',\n",
       "  'ever',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'this',\n",
       "  'country',\n",
       "  ',',\n",
       "  'therefore',\n",
       "  'being',\n",
       "  'a',\n",
       "  'fan',\n",
       "  'of',\n",
       "  'films',\n",
       "  'considered',\n",
       "  'controversial',\n",
       "  'i',\n",
       "  'really',\n",
       "  'had',\n",
       "  'to',\n",
       "  'see',\n",
       "  'this',\n",
       "  'for',\n",
       "  'myself',\n",
       "  '.',\n",
       "  'the',\n",
       "  'plot',\n",
       "  'is',\n",
       "  'centered',\n",
       "  'around',\n",
       "  'a',\n",
       "  'young',\n",
       "  'swedish',\n",
       "  'drama',\n",
       "  'student',\n",
       "  'named',\n",
       "  'lena',\n",
       "  'who',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'everything',\n",
       "  'she',\n",
       "  'can',\n",
       "  'about',\n",
       "  'life',\n",
       "  '.',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'focus',\n",
       "  'her',\n",
       "  'attentions',\n",
       "  'to',\n",
       "  'making',\n",
       "  'some',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'documentary',\n",
       "  'on',\n",
       "  'what',\n",
       "  'the',\n",
       "  'average',\n",
       "  'swede',\n",
       "  'thought',\n",
       "  'about',\n",
       "  'certain',\n",
       "  'political',\n",
       "  'issues',\n",
       "  'such',\n",
       "  'as',\n",
       "  'the',\n",
       "  'vietnam',\n",
       "  'war',\n",
       "  'and',\n",
       "  'race',\n",
       "  'issues',\n",
       "  'in',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  '.',\n",
       "  'in',\n",
       "  'between',\n",
       "  'asking',\n",
       "  'politicians',\n",
       "  'and',\n",
       "  'ordinary',\n",
       "  'denizens',\n",
       "  'of',\n",
       "  'stockholm',\n",
       "  'about',\n",
       "  'their',\n",
       "  'opinions',\n",
       "  'on',\n",
       "  'politics',\n",
       "  ',',\n",
       "  'she',\n",
       "  'has',\n",
       "  'sex',\n",
       "  'with',\n",
       "  'her',\n",
       "  'drama',\n",
       "  'teacher',\n",
       "  ',',\n",
       "  'classmates',\n",
       "  ',',\n",
       "  'and',\n",
       "  'married',\n",
       "  'men',\n",
       "  '.',\n",
       "  'what',\n",
       "  'kills',\n",
       "  'me',\n",
       "  'about',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'is',\n",
       "  'that',\n",
       "  '40',\n",
       "  'years',\n",
       "  'ago',\n",
       "  ',',\n",
       "  'this',\n",
       "  'was',\n",
       "  'considered',\n",
       "  'pornographic',\n",
       "  '.',\n",
       "  'really',\n",
       "  ',',\n",
       "  'the',\n",
       "  'sex',\n",
       "  'and',\n",
       "  'nudity',\n",
       "  'scenes',\n",
       "  'are',\n",
       "  'few',\n",
       "  'and',\n",
       "  'far',\n",
       "  'between',\n",
       "  ',',\n",
       "  'even',\n",
       "  'then',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'not',\n",
       "  'shot',\n",
       "  'like',\n",
       "  'some',\n",
       "  'cheaply',\n",
       "  'made',\n",
       "  'porno',\n",
       "  '.',\n",
       "  'while',\n",
       "  'my',\n",
       "  'countrymen',\n",
       "  'mind',\n",
       "  'find',\n",
       "  'it',\n",
       "  'shocking',\n",
       "  ',',\n",
       "  'in',\n",
       "  'reality',\n",
       "  'sex',\n",
       "  'and',\n",
       "  'nudity',\n",
       "  'are',\n",
       "  'a',\n",
       "  'major',\n",
       "  'staple',\n",
       "  'in',\n",
       "  'swedish',\n",
       "  'cinema',\n",
       "  '.',\n",
       "  'even',\n",
       "  'ingmar',\n",
       "  'bergman',\n",
       "  ',',\n",
       "  'arguably',\n",
       "  'their',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'good',\n",
       "  'old',\n",
       "  'boy',\n",
       "  'john',\n",
       "  'ford',\n",
       "  ',',\n",
       "  'had',\n",
       "  'sex',\n",
       "  'scenes',\n",
       "  'in',\n",
       "  'his',\n",
       "  'films',\n",
       "  '.',\n",
       "  'i',\n",
       "  'do',\n",
       "  'commend',\n",
       "  'the',\n",
       "  'filmmakers',\n",
       "  'for',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'any',\n",
       "  'sex',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'the',\n",
       "  'film',\n",
       "  'is',\n",
       "  'shown',\n",
       "  'for',\n",
       "  'artistic',\n",
       "  'purposes',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'just',\n",
       "  'to',\n",
       "  'shock',\n",
       "  'people',\n",
       "  'and',\n",
       "  'make',\n",
       "  'money',\n",
       "  'to',\n",
       "  'be',\n",
       "  'shown',\n",
       "  'in',\n",
       "  'pornographic',\n",
       "  'theaters',\n",
       "  'in',\n",
       "  'america',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'curious-yellow',\n",
       "  'is',\n",
       "  'a',\n",
       "  'good',\n",
       "  'film',\n",
       "  'for',\n",
       "  'anyone',\n",
       "  'wanting',\n",
       "  'to',\n",
       "  'study',\n",
       "  'the',\n",
       "  'meat',\n",
       "  'and',\n",
       "  'potatoes',\n",
       "  '(',\n",
       "  'no',\n",
       "  'pun',\n",
       "  'intended',\n",
       "  ')',\n",
       "  'of',\n",
       "  'swedish',\n",
       "  'cinema',\n",
       "  '.',\n",
       "  'but',\n",
       "  'really',\n",
       "  ',',\n",
       "  'this',\n",
       "  'film',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'have',\n",
       "  'much',\n",
       "  'of',\n",
       "  'a',\n",
       "  'plot',\n",
       "  '.']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = batch_of_tokens[0][0:100]\n",
    "text[0:100]\n",
    "batch_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41245ce6-6423-41fc-b7b6-a0cb1c420c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be1db85a-e374-4731-aae3-da73b162bb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_of_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2ab707b-6d35-4e0f-bdba-37bc4acc4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 10\n",
    "src_seq,trg_seq = get_sample(block_size,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0e97bec-d8d8-480b-a38d-95d79bf29a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['video',\n",
       "  'store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it'],\n",
       " ['store',\n",
       "  'because',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'controversy',\n",
       "  'that',\n",
       "  'surrounded',\n",
       "  'it',\n",
       "  'when'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq,trg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e3d3bc1-6427-43cd-8040-f0ec7cfbc8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: ['video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it']\n",
      "trg: ['store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when']\n"
     ]
    }
   ],
   "source": [
    "print(f\"src: {src_seq}\")\n",
    "print(f\"trg: {trg_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c638983-9cdc-41f8-b7ac-ebc7af992f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "Source Sequence (Text): ['seized', 'by', 'u', '.', 's', '.', 'customs', 'if', 'it', 'ever']\n",
      "Source Sequence (Indices): [17608, 46, 1466, 3, 17, 3, 11063, 51, 12, 124]\n",
      "Source Sequence (Shape): torch.Size([10])\n",
      "Target Sequence (Text): ['by', 'u', '.', 's', '.', 'customs', 'if', 'it', 'ever', 'tried']\n",
      "Target Sequence (Indices): [46, 1466, 3, 17, 3, 11063, 51, 12, 124, 608]\n",
      "Target Sequence (Shape): torch.Size([10])\n",
      "Sample 1\n",
      "Source Sequence (Text): ['scenes', 'in', 'his', 'films', '.', 'i', 'do', 'commend', 'the', 'filmmakers']\n",
      "Source Sequence (Indices): [144, 14, 39, 129, 3, 13, 81, 11638, 4, 839]\n",
      "Source Sequence (Shape): torch.Size([10])\n",
      "Target Sequence (Text): ['in', 'his', 'films', '.', 'i', 'do', 'commend', 'the', 'filmmakers', 'for']\n",
      "Target Sequence (Indices): [14, 39, 129, 3, 13, 81, 11638, 4, 839, 20]\n",
      "Target Sequence (Shape): torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store source and target\n",
    "src_batch,trg_batch = [],[]\n",
    "\n",
    "# Define batch size\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# Loop to create batches of source and target sequence\n",
    "for i in range(BATCH_SIZE):\n",
    "    _, text = next(iter(train_iter))\n",
    "\n",
    "    # Generate source and target sequences using the get_sample \n",
    "    src_sequence_text, tgt_sequence_text = get_sample(block_size,tokenizer(text))\n",
    "\n",
    "\n",
    "    # Convert source and target sequences to tokenized vocabulary indices\n",
    "    src_sequence_indices = vocab(src_sequence_text)\n",
    "\n",
    "    tgt_sequence_indices = vocab(tgt_sequence_text)\n",
    "\n",
    "    # Convert the sequences to PyTorch Tensors with dtype int64\n",
    "    src_sequence = torch.tensor(src_sequence_indices)\n",
    "    tgt_sequence = torch.tensor(tgt_sequence_indices)\n",
    "\n",
    "    # Append the source and target sequences to their respective batches\n",
    "    src_batch.append(src_sequence)\n",
    "    trg_batch.append(tgt_sequence)\n",
    "\n",
    "    # Print the output for every 2nd sample\n",
    "    print(f\"Sample {i}\")\n",
    "    print(f\"Source Sequence (Text): {src_sequence_text}\")\n",
    "    print(f\"Source Sequence (Indices): {src_sequence_indices}\")\n",
    "    print(f\"Source Sequence (Shape): {src_sequence.shape}\")\n",
    "    print(f\"Target Sequence (Text): {tgt_sequence_text}\")\n",
    "    print(f\"Target Sequence (Indices): {tgt_sequence_indices}\")\n",
    "    print(f\"Target Sequence (Shape): {tgt_sequence.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fc7efc4-da3e-4baf-9295-0a8c26c54332",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 30\n",
    "\n",
    "def collate_batch(batch):\n",
    "\n",
    "    src_batch,tgt_batch = [], []\n",
    "\n",
    "    for _,text in batch:\n",
    "        tokens = tokenizer(text)\n",
    "        src_tokens,tgt_tokens = get_sample(block_size,tokens)\n",
    "        src_indices,tgt_indices = vocab(src_tokens),vocab(tgt_tokens)\n",
    "        src_sequences,tgt_sequences = torch.tensor(src_indices,dtype = torch.int64),torch.tensor(tgt_indices,dtype = torch.int64)\n",
    "        src_batch.append(src_sequences)\n",
    "        tgt_batch.append(tgt_sequences)\n",
    "\n",
    "\n",
    "    src_batch = pad_sequence(src_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "    tgt_batch = pad_sequence(tgt_batch,padding_value = PAD_IDX, batch_first = False)\n",
    "\n",
    "    return src_batch.to(DEVICE),tgt_batch.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c4c0686-8f1a-4ed9-b55c-a782c94754d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da578e3a-26df-448d-8088-02f962a0f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_iter,\n",
    "                       batch_size =BATCH_SIZE,\n",
    "                       shuffle = True,\n",
    "                       collate_fn = collate_batch)\n",
    "\n",
    "val_dataloader = DataLoader(valid_iter,\n",
    "                       batch_size =BATCH_SIZE,\n",
    "                       shuffle = True,\n",
    "                       collate_fn = collate_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e2485-e702-42d2-ae6e-506680ca92b5",
   "metadata": {},
   "source": [
    "## Iterating Through Data Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598263d9-af37-4213-ade8-909b179336a7",
   "metadata": {},
   "source": [
    "`dataset`, an iterator is formed to run over the dataloader, which in return provide src and tgt pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db9e35fe-19bf-455c-a78e-d9bfe8e3485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "sorce: s keen aspiration to pay homage to ozu on his\n",
      "\n",
      "\n",
      "target: keen aspiration to pay homage to ozu on his centenary\n",
      "\n",
      "\n",
      "sample 1\n",
      "sorce: to be an ankylosaur seriously ? and the tyrannosaur seems\n",
      "\n",
      "\n",
      "target: be an ankylosaur seriously ? and the tyrannosaur seems rooted\n",
      "\n",
      "\n",
      "sample 2\n",
      "sorce: annoying . and the saddest thing is the movie is\n",
      "\n",
      "\n",
      "target: . and the saddest thing is the movie is too\n",
      "\n",
      "\n",
      "sample 3\n",
      "sorce: this move had , the reality was disappointing . while\n",
      "\n",
      "\n",
      "target: move had , the reality was disappointing . while it\n",
      "\n",
      "\n",
      "sample 4\n",
      "sorce: i kept watching this hoping that i could see why\n",
      "\n",
      "\n",
      "target: kept watching this hoping that i could see why it\n",
      "\n",
      "\n",
      "sample 5\n",
      "sorce: mr . dark , what happened to mr . coogan\n",
      "\n",
      "\n",
      "target: . dark , what happened to mr . coogan on\n",
      "\n",
      "\n",
      "sample 6\n",
      "sorce: dont know who wrote the script but i bet they\n",
      "\n",
      "\n",
      "target: know who wrote the script but i bet they got\n",
      "\n",
      "\n",
      "sample 7\n",
      "sorce: . it seems to me whomever made this movie is\n",
      "\n",
      "\n",
      "target: it seems to me whomever made this movie is afflicted\n",
      "\n",
      "\n",
      "sample 8\n",
      "sorce: line by filling this movie with totally unsympathetic and almost\n",
      "\n",
      "\n",
      "target: by filling this movie with totally unsympathetic and almost masochistic\n",
      "\n",
      "\n",
      "sample 9\n",
      "sorce: . . . oh wait i must be thinking of\n",
      "\n",
      "\n",
      "target: . . oh wait i must be thinking of a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = iter(dataloader)\n",
    "for sample in range(10):\n",
    "    src,tgt = next(dataset)\n",
    "    print(\"sample\",sample)\n",
    "    print(\"sorce:\",index_to_en(src))\n",
    "    print(\"\\n\")\n",
    "    print(\"target:\",index_to_en(tgt))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06d930d6-2e6f-46b8-bf40-a3ed09918182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_en(batch):\n",
    "    return \" \".join([vocab.get_itos()[idx] for idx in batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7aac78-2e42-42a4-9b79-09c4be2476df",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8541e55e-e919-4054-baac-82ade95ee262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz,device = DEVICE):\n",
    "    mask = (torch.triu(torch.ones((sz,sz),device = device))==1).transpose(0,1)\n",
    "    mask = mask.float().masked_fill(mask ==0,float ('-inf')).masked_fill(mask ==1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4cab571-f237-45b5-8c23-10f7bffed50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src, device = DEVICE):\n",
    "    src_seq_len = src.shape[0]\n",
    "    src_mask = generate_square_subsequent_mask(src_seq_len)\n",
    "    src_padding_mask = (src ==PAD_IDX).transpose(0,1)\n",
    "    return src_mask,src_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee527d4-17b3-4ae2-88d7-0f7bb67ebf3c",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "598dc4cb-5107-4bc3-be11-d26c725d91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                emb_dim: int,\n",
    "                dropout: float,\n",
    "                maxlen: int = 5000):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        den = torch.exp(-torch.arange(0,emb_dim,2)*math.log(10000)/emb_dim)\n",
    "        pos = torch.arange(0,maxlen).reshape(maxlen,1)\n",
    "        pos_embedding = torch.zeros(size = (maxlen,emb_dim))\n",
    "\n",
    "        pos_embedding[:,0::2] = torch.sin(pos*den)\n",
    "        pos_embedding[:,1::2] = torch.cos(pos*den)\n",
    "\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self,token_embedding):\n",
    "        return self.dropout(token_embedding +self.pos_embedding[:token_embedding.size(0),:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c0d65-70df-46a5-bad0-6e11c2dbcbf5",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3523767-d1c8-4e99-8a84-70e6c615b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,emb_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def forward(self,tokens):\n",
    "\n",
    "        return self.embedding(tokens.long())* math.sqrt(self.emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53900747-0c20-49aa-b7ad-e930de1d90a0",
   "metadata": {},
   "source": [
    "## Custom GPT model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead70349-548d-4561-aabe-a839d309f8b1",
   "metadata": {},
   "source": [
    "* Initialization (__init__): embed_size, vocab_size, num_heads,num_layers,max_seq_len and dropout\n",
    "* lm_head: generating logits over the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23af57-f0d5-46bc-ae7b-013cbbb1ace5",
   "metadata": {},
   "source": [
    "* **Weight initialization** initializes the weights of the model for better training convergence. The Xavier uniform initialization is used, which is a common practice for initializing weights in deep learning\n",
    "* **Decoder** Although named `'decoder'`, this method currently functions as the forward pass through the transformer encoder layers, followed by the generation of `logits` for the language modelling task. It handles the addition of positional encodings to the embeddings and applies a mask if necessary.\n",
    "* **Forward pass**: This method is similar to the `decoder` method, and defines the forward computation of the model. It produces the input through embedding layers, positional encoding, transformer encoder layers, and produces the final output using the `lm_head`\n",
    "* **Mask Generation:** Both **decoder** and **forward** methods contain logic to generate a square causal mask if no source mask is provided.\n",
    "mask ensures that the prediction for a position does not depend on the future tokens in the sequence, which is important for the autoregressive nature of gpt models.\n",
    "* **Commented Out Decoder**: A section of the code is commented out, suggesting an initial design where a transformer decoder layer was considered. However, the final implementation uses only encoder layers, which is a common simplification for models focusing on language modeling and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5f1ba59-0bba-4c86-ae15-6058a33196e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self,emb_dim:int,\n",
    "                vocab_size: int,\n",
    "                num_heads: int,\n",
    "                num_layers: int,\n",
    "                max_seq_len = 500,\n",
    "                 dropout = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(emb_dim = emb_dim,\n",
    "                                                     dropout = dropout)\n",
    "\n",
    "        print(emb_dim)\n",
    "\n",
    "        # Remaining layers are part of the TransformerDecoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model = emb_dim,\n",
    "                                                   nhead = num_heads,\n",
    "                                                   dropout = dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layers,\n",
    "                                                        num_layers=num_layers)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size) # produce the final output, the final logits over the vocabulary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim()>1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def create_mask(src, device = DEVICE):\n",
    "        src_seq_len = src.shape[0]\n",
    "        src_mask = nn.Transformer.generate_square_subsequent_mask(src_seq_len)\n",
    "        src_padding_mask = (src ==PAD_IDX).transpose(0,1)\n",
    "        return src_mask, src_padding_mask\n",
    "\n",
    "    def decoder(self, x, src_mask):\n",
    "        seq_len = x.size(0)\n",
    "\n",
    "\n",
    "        # Add positional embeddings to the input embeddings\n",
    "        x = self.embed(x)*math.sqrt(self.emb_dim)\n",
    "\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "\n",
    "        if src_mask is None:\n",
    "            \"\"\"Generate a square casual mask for the sequence. The masked positions are filled with -inf and the unmasked postions will be filled with 0\"\"\"\n",
    "\n",
    "            src_mask, src_padding_mask =create_mask(x)\n",
    "\n",
    "        output = self.transformer_encoder(x,src_mask)\n",
    "        logits = self.lm_head(output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def forward(self,x, src_mask = None, key_padding_mask = None):\n",
    "\n",
    "        seq_length = x.size(0)\n",
    "\n",
    "        embedding = self.embed(x) * math.sqrt(self.emb_dim)\n",
    "        x = self.positional_encoding(embedding)\n",
    "\n",
    "        if src_mask is None:\n",
    "            src_mask,src_padding_mask = create_mask(x)\n",
    "\n",
    "        output = self.transformer_encoder(x,src_mask, key_padding_mask)\n",
    "\n",
    "        x = self.lm_head(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83bcd08-80b9-44c6-9b1f-b46fae5d70e3",
   "metadata": {},
   "source": [
    "## Model Configaration and initializaion\n",
    "Here, we configure and instantiate a Custom GPT Model with the following specifications:\n",
    "\n",
    "- `ntokens`: The total number of unique tokens in the vocabulary, which the model will use to represent words.\n",
    "- `emsize`: The size of each embedding vector. In this model, each word will be represented by a 200-dimensional vector.\n",
    "- `nlayers`: The number of transformer encoder layers in the model. We are using two layers in this configuration.\n",
    "- `nhead`: The number of attention heads in the multi-head attention mechanism. The model will use two attention heads.\n",
    "- `dropout`: A regularization technique where randomly selected neurons are ignored during training to prevent overfitting. Here, we set the dropout probability to 0.2.\n",
    "\n",
    "After setting these hyperparameters, we create an instance of `CustomGPTModel` by passing in the embedding size, number of attention heads, number of layers, vocabulary size, and dropout probability. The model is then moved to the specified `DEVICE`, which could be a CPU or GPU, for training or inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4aec4923-cab9-4c06-a980-aab4e0fb3144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "ntokens = len(vocab)\n",
    "emb_dim = 200 \n",
    "nlayers = 2 \n",
    "nhead = 2\n",
    "dropout = 0.2\n",
    "\n",
    "model = CustomGPTModel(emb_dim = emb_dim,\n",
    "                      vocab_size = ntokens,\n",
    "                      num_heads=nhead,\n",
    "                      num_layers=nlayers,\n",
    "                      dropout = dropout).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3d827-5561-4e97-926b-0509484d1784",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40122831-cca1-4e7b-945c-d7dd6b52e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_prompt(prompt, block_size = BLOCK_SIZE):\n",
    "\n",
    "    # Handle none prompt\n",
    "    while prompt is None:\n",
    "        prompt = input(\"Sorry, prompt cannot be empty. Please enter a valid prompt\")\n",
    "\n",
    "    tokens = tokenizer(prompt)\n",
    "    number_of_tokens = len(tokens)\n",
    "\n",
    "    # Handle long prompt\n",
    "    if number_of_tokens>block_size:\n",
    "        tokens = tokens[-block_size:]\n",
    "\n",
    "    prompt_indices = vocab(tokens)\n",
    "\n",
    "    prompt_encoded = torch.tensor(prompt_indices,dtype = torch.int64).reshape(-1,1)\n",
    "    \n",
    "\n",
    "    return prompt_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78aa31a7-cddf-40c4-a0e8-e9fb71a1bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sorry, prompt cannot be empty. Please enter a valid prompt Neyman is the best footballer in the world\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> is the best footballer in the world\n"
     ]
    }
   ],
   "source": [
    "print(index_to_en(encode_prompt(None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2dd572f3-bd86-471a-b544-74783668309d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 15],\n",
      "        [ 11],\n",
      "        [ 72],\n",
      "        [256],\n",
      "        [806],\n",
      "        [ 10],\n",
      "        [ 26],\n",
      "        [ 40]])\n"
     ]
    }
   ],
   "source": [
    "print(encode_prompt(\"This is my last message to you all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6878bc05-2afc-4ddc-a591-7528efe11eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0],\n",
       "        [ 11],\n",
       "        [  4],\n",
       "        [178]], device='mps:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_encoded = encode_prompt(\"Neymar is the best\").to(DEVICE)\n",
    "prompt_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e43a3680-a151-4d87-8d52-1aac05f6b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.decoder(prompt_encoded,src_mask=None).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e9fd4ce7-027e-497d-af4c-093f5c03d395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 68813])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99c70531-b92f-423a-a5d4-2f2daa3f1edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 68813])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits.transpose(0,1)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c772aa79-acb3-4a8d-8572-15ae31b9d98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 68813])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_prediction = logits[:,-1]\n",
    "logit_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1fcf5e6f-39a0-44d1-bc2d-987af0e9e510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([52875], device='mps:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,next_word_index = torch.max(logit_prediction, dim = 1)\n",
    "next_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "456e7871-bfc3-4089-a594-ba744cf938fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lesser-sitcom'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_en(next_word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f69371e-ca4a-4a05-b2ec-fb90b91b182f",
   "metadata": {},
   "source": [
    "## Autoregressive text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "21cebcbc-f0ca-46ec-a981-e2d747f8c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"This is the beginning of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "534c32a1-3d9b-4078-ab99-bfda8bd3e66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for prompt encoded: torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "prompt_encoded = encode_prompt(prompt).to(DEVICE)\n",
    "print(\"Device for prompt encoded:\",prompt_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2364983b-9cbf-4fe5-adc9-6c8c3895ebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Shape of logits at step 0 torch.Size([1, 5, 68813])\n",
      "Shape of logit prediction at step 0: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 0 : torch.Size([1, 1])\n",
      "Sequence for step0: ['this', 'is', 'the', 'beginning', 'of', '*martin']\n",
      "Shape: torch.Size([6, 1])\n",
      " \n",
      "Shape of logits at step 1 torch.Size([1, 6, 68813])\n",
      "Shape of logit prediction at step 1: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 1 : torch.Size([1, 1])\n",
      "Sequence for step1: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic']\n",
      "Shape: torch.Size([7, 1])\n",
      " \n",
      "Shape of logits at step 2 torch.Size([1, 7, 68813])\n",
      "Shape of logit prediction at step 2: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 2 : torch.Size([1, 1])\n",
      "Sequence for step2: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety']\n",
      "Shape: torch.Size([8, 1])\n",
      " \n",
      "Shape of logits at step 3 torch.Size([1, 8, 68813])\n",
      "Shape of logit prediction at step 3: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 3 : torch.Size([1, 1])\n",
      "Sequence for step3: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety', 'games-']\n",
      "Shape: torch.Size([9, 1])\n",
      " \n",
      "Shape of logits at step 4 torch.Size([1, 9, 68813])\n",
      "Shape of logit prediction at step 4: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 4 : torch.Size([1, 1])\n",
      "Sequence for step4: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety', 'games-', 'undesirables']\n",
      "Shape: torch.Size([10, 1])\n",
      " \n",
      "Shape of logits at step 5 torch.Size([1, 10, 68813])\n",
      "Shape of logit prediction at step 5: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 5 : torch.Size([1, 1])\n",
      "Sequence for step5: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety', 'games-', 'undesirables', 'sludge']\n",
      "Shape: torch.Size([11, 1])\n",
      " \n",
      "Shape of logits at step 6 torch.Size([1, 11, 68813])\n",
      "Shape of logit prediction at step 6: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 6 : torch.Size([1, 1])\n",
      "Sequence for step6: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety', 'games-', 'undesirables', 'sludge', 'gelatinous']\n",
      "Shape: torch.Size([12, 1])\n",
      " \n",
      "Shape of logits at step 7 torch.Size([1, 12, 68813])\n",
      "Shape of logit prediction at step 7: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 7 : torch.Size([1, 1])\n",
      "Sequence for step7: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety', 'games-', 'undesirables', 'sludge', 'gelatinous', '=']\n",
      "Shape: torch.Size([13, 1])\n",
      " \n",
      "Shape of logits at step 8 torch.Size([1, 13, 68813])\n",
      "Shape of logit prediction at step 8: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 8 : torch.Size([1, 1])\n",
      "Sequence for step8: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety', 'games-', 'undesirables', 'sludge', 'gelatinous', '=', 'scheider']\n",
      "Shape: torch.Size([14, 1])\n",
      " \n",
      "Shape of logits at step 9 torch.Size([1, 14, 68813])\n",
      "Shape of logit prediction at step 9: torch.Size([1, 68813])\n",
      "Shape of next token encoded at step 9 : torch.Size([1, 1])\n",
      "Sequence for step9: ['this', 'is', 'the', 'beginning', 'of', '*martin', 'voyeuristic', 'rickety', 'games-', 'undesirables', 'sludge', 'gelatinous', '=', 'scheider', 'suess']\n",
      "Shape: torch.Size([15, 1])\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens = 10\n",
    "\n",
    "for i in range(max_new_tokens):\n",
    "\n",
    "    logits = model.decoder(prompt_encoded,src_mask = None)\n",
    "    logits = logits.transpose(0,1)\n",
    "\n",
    "    print(\" \")\n",
    "    print(f\"Shape of logits at step {i} {logits.shape}\")\n",
    "\n",
    "    logit_prediction = logits[:,-1]\n",
    "    print(f\"Shape of logit prediction at step {i}: {logit_prediction.shape}\")\n",
    "\n",
    "    next_token_encoded = torch.argmax(logit_prediction,dim = 1).reshape(-1,1)\n",
    "    print(f\"Shape of next token encoded at step {i} : {next_token_encoded.shape}\")\n",
    "\n",
    "    prompt_encoded = torch.cat((prompt_encoded, next_token_encoded),dim = 0).to(DEVICE)\n",
    "    print(f\"Sequence for step{i}: {[index_to_en(j) for j in prompt_encoded]}\")\n",
    "    print(f\"Shape: {prompt_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d2c77b47-a0dc-4115-87b9-04d7a7568b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK_IDX, PAD_IDX, EOS_IDX = 0,1,2\n",
    "\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>','<pad>','<|endoftext|>']\n",
    "BLOCK_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87308fbb-d38e-4424-9f37-f1ff69c1e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto regressive language model text generation\n",
    "def generate(model, prompt = None, max_new_tokens = 500, block_size = BLOCK_SIZE,vocab = vocab, tokenizer = tokenizer):\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Encode the input prompt\n",
    "    prompt_encoded = encode_prompt(prompt).to(DEVICE) # return the indices number in a tensor form\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    # Generate new tokens up to max_new_tokens\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Decode the input prompt using the provided encode_prompt function\n",
    "        logits = model(prompt_encoded, src_mask = None, key_padding_mask = None)\n",
    "\n",
    "        # Transpose the logits to bring the sequence length to the first diemnsion\n",
    "        logits = logits.transpose(0,1)\n",
    "\n",
    "        # select the logits of the last token in the sequence\n",
    "        logit_prediction = logits[:,-1]\n",
    "\n",
    "        # choose the most probable next token from the logits(greedy decoding)\n",
    "        next_token_encoded = torch.argmax(logit_prediction, dim = -1).reshape(-1,1)\n",
    "\n",
    "        # if the next token is the end of sequence(EOS) token, stop generation\n",
    "        if next_token_encoded.item() == EOS_IDX:\n",
    "            break\n",
    "\n",
    "        # Append the next token to the prompt encoded and keep only the last 'block_size' tokens\n",
    "        prompt_encoded = torch.cat((prompt_encoded, next_token_encoded),dim = 0) [-block_size:]\n",
    "\n",
    "        # Convert the next token index to a token string using c\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c151564-cc19-44d4-a814-7c032b695ede",
   "metadata": {},
   "source": [
    "## Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6beef990-6633-4dda-9ad6-791172c25aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "# import the libraries\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset,DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0c87d458-c75c-4539-b77b-a56776730627",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect the dataset\n",
    "from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "32446a74-4e36-4fb1-8ee1-97500f6ce72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77352097-7ea7-43f5-b105-bcd12826a1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample = next(iter(train_iter))\n",
    "train_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3271c39a-dcd9-4184-a9d1-33a05c4799cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(texts):\n",
    "    for _,text in texts:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f5ee91e-bc7a-4a3a-8b0f-2f155888f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = yield_tokens(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b22a718c-d627-4d6c-8e0f-2cc7647c0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8febe35-7374-4b1b-85eb-1c46ae823b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary from the tokens\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "448d75ab-4fd9-42c4-a717-402c05a6a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68810"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b22b3-c5ba-4d27-9ab4-96529296a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokens of the whole dataset\n",
    "# get the vocab \n",
    "# create the embedding\n",
    "class Embedding(nn.Module):\n",
    "    def __i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93576263-320c-478b-a6ea-1adce12e32bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_t = torch.ones(3,3)\n",
    "one_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73653b1-201b-45f1-8355-fd40d0c30060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db049ed4-20ae-4614-98b8-a00fa9925680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75f2b9fe-04b4-4f40-9e94-4674ee0f43d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_t = torch.triu(one_t)\n",
    "upper_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ae95385-f6ce-48d4-a0dc-c368560918a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True],\n",
       "        [False,  True,  True],\n",
       "        [False, False,  True]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru = upper_t==1\n",
    "tru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9d54b85-d06e-45c9-8a0d-b070559bb1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru_trans = tru.transpose(0,1)\n",
    "tru_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517527c-6748-45d2-9825-c1c3dc896aad",
   "metadata": {},
   "source": [
    "## Decoder WorkPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6679382-0da2-4bcd-8b46-075e338934df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11b9de04-405f-4260-84d2-740582233d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchtext.datasets import Multi30k,multi30k\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "\n",
    "import nltk\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args,**kwargs):\n",
    "    pass\n",
    "warnings.warn = warn()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15ce97-6ef2-43dc-bc97-12ef3a8fc669",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d5e13b-1132-4a17-a1fa-725b28d83452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "train_iter, test_iter = IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4251f3e-6427-4071-88cd-152ce81fe22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label,sample = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35233756-3557-44c8-8098-7d1745266dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label,sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e1bd76-997f-4f0e-b159-09020c382dd2",
   "metadata": {},
   "source": [
    "The dataset contains reviews about a number a movies. Reviewers labelled the movie as 1 or 0. while 1 indicates that the movie review is tend to positive and 0 indicates that the movie review is not that good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "317ad961-f677-4860-a677-60714cd2b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list =set([label for label,_ in train_iter])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7e64c8b-a6fd-42e0-bb81-80815f2ab199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a706d-9a54-48c9-8a10-c2f4e9b7b083",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a17b7-03e7-4942-a60d-7eb2aac9acba",
   "metadata": {},
   "source": [
    "* Padding\n",
    "* Unk_idx, pad_idx,\n",
    "* index to text\n",
    "* text to idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b84cc-3021-488c-a539-584ddbe1bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX,PAD_IDX,EOS_IDX = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3df7bcf6-1b8e-43c7-8207-6f3978221e83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Declare tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "## Tokenization\n",
    "def yield_token(dataset):\n",
    "    for label,text in dataset:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76e3877c-77c2-44bd-86cd-b4363b4b6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = yield_token(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0003a152-da18-4560-bd69-e4233df11630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'rented',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'from',\n",
       " 'my',\n",
       " 'video',\n",
       " 'store',\n",
       " 'because',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'controversy',\n",
       " 'that',\n",
       " 'surrounded',\n",
       " 'it',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1967',\n",
       " '.',\n",
       " 'i',\n",
       " 'also',\n",
       " 'heard',\n",
       " 'that',\n",
       " 'at',\n",
       " 'first',\n",
       " 'it',\n",
       " 'was',\n",
       " 'seized',\n",
       " 'by',\n",
       " 'u',\n",
       " '.',\n",
       " 's',\n",
       " '.',\n",
       " 'customs',\n",
       " 'if',\n",
       " 'it',\n",
       " 'ever',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'this',\n",
       " 'country',\n",
       " ',',\n",
       " 'therefore',\n",
       " 'being',\n",
       " 'a',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'films',\n",
       " 'considered',\n",
       " 'controversial',\n",
       " 'i',\n",
       " 'really',\n",
       " 'had',\n",
       " 'to',\n",
       " 'see',\n",
       " 'this',\n",
       " 'for',\n",
       " 'myself',\n",
       " '.',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'is',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'a',\n",
       " 'young',\n",
       " 'swedish',\n",
       " 'drama',\n",
       " 'student',\n",
       " 'named',\n",
       " 'lena',\n",
       " 'who',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'everything',\n",
       " 'she',\n",
       " 'can',\n",
       " 'about',\n",
       " 'life',\n",
       " '.',\n",
       " 'in',\n",
       " 'particular',\n",
       " 'she',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'her',\n",
       " 'attentions',\n",
       " 'to',\n",
       " 'making',\n",
       " 'some',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'documentary',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'average',\n",
       " 'swede',\n",
       " 'thought',\n",
       " 'about',\n",
       " 'certain',\n",
       " 'political',\n",
       " 'issues',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'vietnam',\n",
       " 'war',\n",
       " 'and',\n",
       " 'race',\n",
       " 'issues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " '.',\n",
       " 'in',\n",
       " 'between',\n",
       " 'asking',\n",
       " 'politicians',\n",
       " 'and',\n",
       " 'ordinary',\n",
       " 'denizens',\n",
       " 'of',\n",
       " 'stockholm',\n",
       " 'about',\n",
       " 'their',\n",
       " 'opinions',\n",
       " 'on',\n",
       " 'politics',\n",
       " ',',\n",
       " 'she',\n",
       " 'has',\n",
       " 'sex',\n",
       " 'with',\n",
       " 'her',\n",
       " 'drama',\n",
       " 'teacher',\n",
       " ',',\n",
       " 'classmates',\n",
       " ',',\n",
       " 'and',\n",
       " 'married',\n",
       " 'men',\n",
       " '.',\n",
       " 'what',\n",
       " 'kills',\n",
       " 'me',\n",
       " 'about',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'is',\n",
       " 'that',\n",
       " '40',\n",
       " 'years',\n",
       " 'ago',\n",
       " ',',\n",
       " 'this',\n",
       " 'was',\n",
       " 'considered',\n",
       " 'pornographic',\n",
       " '.',\n",
       " 'really',\n",
       " ',',\n",
       " 'the',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'scenes',\n",
       " 'are',\n",
       " 'few',\n",
       " 'and',\n",
       " 'far',\n",
       " 'between',\n",
       " ',',\n",
       " 'even',\n",
       " 'then',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'not',\n",
       " 'shot',\n",
       " 'like',\n",
       " 'some',\n",
       " 'cheaply',\n",
       " 'made',\n",
       " 'porno',\n",
       " '.',\n",
       " 'while',\n",
       " 'my',\n",
       " 'countrymen',\n",
       " 'mind',\n",
       " 'find',\n",
       " 'it',\n",
       " 'shocking',\n",
       " ',',\n",
       " 'in',\n",
       " 'reality',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'are',\n",
       " 'a',\n",
       " 'major',\n",
       " 'staple',\n",
       " 'in',\n",
       " 'swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'even',\n",
       " 'ingmar',\n",
       " 'bergman',\n",
       " ',',\n",
       " 'arguably',\n",
       " 'their',\n",
       " 'answer',\n",
       " 'to',\n",
       " 'good',\n",
       " 'old',\n",
       " 'boy',\n",
       " 'john',\n",
       " 'ford',\n",
       " ',',\n",
       " 'had',\n",
       " 'sex',\n",
       " 'scenes',\n",
       " 'in',\n",
       " 'his',\n",
       " 'films',\n",
       " '.',\n",
       " 'i',\n",
       " 'do',\n",
       " 'commend',\n",
       " 'the',\n",
       " 'filmmakers',\n",
       " 'for',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'any',\n",
       " 'sex',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'the',\n",
       " 'film',\n",
       " 'is',\n",
       " 'shown',\n",
       " 'for',\n",
       " 'artistic',\n",
       " 'purposes',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'just',\n",
       " 'to',\n",
       " 'shock',\n",
       " 'people',\n",
       " 'and',\n",
       " 'make',\n",
       " 'money',\n",
       " 'to',\n",
       " 'be',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'pornographic',\n",
       " 'theaters',\n",
       " 'in',\n",
       " 'america',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'film',\n",
       " 'for',\n",
       " 'anyone',\n",
       " 'wanting',\n",
       " 'to',\n",
       " 'study',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'and',\n",
       " 'potatoes',\n",
       " '(',\n",
       " 'no',\n",
       " 'pun',\n",
       " 'intended',\n",
       " ')',\n",
       " 'of',\n",
       " 'swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'but',\n",
       " 'really',\n",
       " ',',\n",
       " 'this',\n",
       " 'film',\n",
       " 'doesn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'have',\n",
       " 'much',\n",
       " 'of',\n",
       " 'a',\n",
       " 'plot',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Vocabulary\n",
    "vocab = build_vocab_from_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8829e9-f230-4a39-97b7-0aa9cc569740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
